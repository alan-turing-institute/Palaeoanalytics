{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to PyLithics","text":""},{"location":"#archaeological-lithic-analysis-with-computer-vision","title":"Archaeological Lithic Analysis with Computer Vision","text":"<p>PyLithics is an open-source Python package that applies advanced computer vision techniques to extract quantitative morphological data from 2D line drawings of prehistoric stone artifacts.</p>"},{"location":"#what-is-pylithics","title":"What is PyLithics?","text":"<p>PyLithics processes scanned 2D illustrations of stone tools (lithics) from archaeological publications, automatically identifying and measuring key technological and morphological features. The tool has been optimized for feature extraction using cutting-edge computer vision techniques including:</p> <ul> <li>Pixel intensity thresholding</li> <li>Edge detection and contour finding</li> <li>Custom template matching</li> <li>Advanced geometric analysis</li> <li>Machine learning-based feature recognition</li> </ul>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#accurate-surface-identification","title":"Accurate Surface Identification","text":"<ul> <li>Automatically identifies dorsal, ventral, platform, and lateral surfaces</li> <li>Recognizes individual flake scars with high precision</li> <li>Detect cortex areas</li> <li>Configurable detection parameters for different drawing styles</li> </ul>"},{"location":"#comprehensive-measurements","title":"Comprehensive Measurements","text":"<ul> <li>Complete size and shape metrics for whole flakes and individual scars</li> <li>Technical dimensions (length, width, thickness)</li> <li>Geometric properties (area, perimeter, aspect ratios)</li> <li>Symmetry analysis (vertical and horizontal)</li> <li>Scar complexity and adjacency relationships</li> </ul>"},{"location":"#advanced-analysis","title":"Advanced Analysis","text":"<ul> <li>Flaking direction detection through arrow recognition</li> <li>Voronoi diagram generation for spatial analysis</li> <li>Convex hull calculations</li> <li>Lateral edge convexity analysis</li> <li>Configurable analysis modules that can be enabled/disabled</li> </ul>"},{"location":"#configuration-and-customization","title":"Configuration and Customization","text":"<p>PyLithics offers extensive configuration options through both YAML configuration files and command-line arguments:</p> <ul> <li>Adjust thresholding methods (simple, Otsu, adaptive)</li> <li>Enable/disable specific analysis modules</li> <li>Fine-tune detection parameters</li> <li>Customize output formats</li> </ul>"},{"location":"#research-ready-output","title":"Research-Ready Output","text":"<ul> <li>Structured CSV data output with hierarchical organization</li> <li>Annotated visualization images for validation</li> <li>Comprehensive logging for reproducibility</li> <li>Compatible with standard statistical analysis software</li> </ul>"},{"location":"#why-pylithics","title":"Why PyLithics?","text":""},{"location":"#for-researchers","title":"For Researchers","text":"<ul> <li>Time-Saving: Automate hours of manual measurement</li> <li>Consistency: Eliminate inter-observer variability</li> <li>Scale: Process entire assemblages efficiently</li> <li>Reproducibility: Ensure consistent, replicable results</li> </ul>"},{"location":"#for-archaeological-science","title":"For Archaeological Science","text":"<ul> <li>Quantitative Analysis: Move beyond qualitative descriptions</li> <li>Pattern Recognition: Identify subtle technological variations</li> <li>Big Data: Enable large-scale comparative studies</li> <li>Open Science: Free, open-source tool for the community</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<ol> <li>Installation Guide - Set up PyLithics on your system</li> <li>User Guide - Learn how to use PyLithics effectively</li> <li>Image Requirements - Prepare your lithic illustrations</li> <li>Basic Usage - Run your first analysis</li> </ol> <p>See the CLI Commands Reference for complete configuration options.</p>"},{"location":"#support-and-contributing","title":"Support and Contributing","text":"<p>PyLithics is actively developed and maintained. We welcome contributions from the archaeological and computer science communities.</p> <ul> <li>Issues: Report bugs or request features on GitHub</li> <li>Contributing: See our Contributing Guidelines</li> <li>Contact: Reach out to the team</li> </ul>"},{"location":"#citation","title":"Citation","text":"<p>If you use PyLithics in your research, please cite:</p> <p></p>"},{"location":"#license","title":"License","text":"<p>PyLithics is licensed under the GNU General Public License v3.0</p>"},{"location":"about/","title":"About PyLithics","text":""},{"location":"about/#the-project","title":"The Project","text":"<p>PyLithics began as part of the Palaeoanalytics project (ended), a collaboration between The Alan Turing Institute and the University of Cambridge, led by Professor Robert Foley. After the original Palaeoanalytics project ended, PyLithics software development has continued as part of the British Academy funded project \"Transitions in early stone tool technologies: a computer vision and machine learning approach\" (ongoing) led by Dr. Jason Gellis. These innovative projects seek to apply cutting-edge machine learning and computer vision techniques to archaeological research, specifically focusing on the feature extraction and quantitative analysis of prehistoric stone tools from 2D illustrations.</p>"},{"location":"about/#research-impact","title":"Research Impact","text":"<p>PyLithics has been designed to support multiple types of archaeological research:</p>"},{"location":"about/#methodological-advances","title":"Methodological Advances","text":"<ul> <li>Quantitative analysis of lithic assemblages</li> <li>Standardization of measurement protocols</li> <li>Reduction of inter-observer variability</li> <li>Large-scale comparative studies</li> </ul>"},{"location":"about/#archaeological-applications","title":"Archaeological Applications","text":"<ul> <li>Technological analysis of prehistoric industries</li> <li>Cultural transmission studies</li> <li>Skill assessment in prehistoric populations</li> <li>Temporal and spatial variation in tool-making traditions</li> </ul>"},{"location":"about/#open-science-commitment","title":"Open Science Commitment","text":"<p>PyLithics embodies principles of open science:</p> <ul> <li>Open Source: All code is freely available under GPL v3.0</li> <li>Transparent Methods: Processing algorithms are fully documented</li> <li>Reproducible Research: Analysis parameters are recorded and sharable</li> <li>Community Driven: Development guided by user needs and feedback</li> </ul>"},{"location":"about/#the-team","title":"The Team","text":"<p>Dr. Jason Gellis</p> <ul> <li>British Academy Post-Doctoral Research Fellow (University of Cambridge)</li> <li>jg760@cam.ac.uk</li> <li>@JasonGellis</li> </ul> <p>Dr. Gellis leads the technical development of PyLithics and brings expertise in computer vision, machine learning, and archaeological methodology. He has been involved in the project at all stages and currently leads PyLithics development as part of his British Academy funded research. His research focuses on the intersection of computational methods and archaeological science.</p> <p>Prof. Robert Foley</p> <ul> <li>Principal Investigator (University of Cambridge)</li> <li>raf10@cam.ac.uk</li> <li>@Rob-LCHES</li> </ul> <p>Professor Foley is an evolutionary and biological anthropologist with research interests in human evolution, particularly the ecological basis for patterns and processes of human behavioural evolution. His work covers social evolution, speciation and extinction in hominins, hunter-gatherer ecology, and the origins of modern humans, applying evolutionary models to human evolution through both palaeobiological and contemporary biological methods. He has contributed extensively to the development of the African origin of modern humans field, working across fossils, genetics and archaeology, and is currently engaged in field projects focusing on the evolution of modern humans in Africa. Professor Foley led the Alan Turing Institute portion of the original Palaeoanalytics project and continues to participate in PyLithics development as an advisor, providing archaeological expertise and project oversight.</p> <p>Dr. Camila Rangel Smith</p> <ul> <li>Research Data Scientist (The Alan Turing Institute)</li> <li>crangelsmith@turing.ac.uk</li> </ul> <p>Dr. Rangel Smith contributed data science expertise during the initial Alan Turing Institute phase of the project, helping to bridge the gap between advanced computational methods and practical archaeological applications.</p>"},{"location":"about/#institutional-affiliations","title":"Institutional Affiliations","text":""},{"location":"about/#the-british-academy","title":"The British Academy","text":"<p>The UK's national academy for the humanities and social sciences, currently funding the ongoing PyLithics development through the \"Transitions in early stone tool technologies\" project, enabling continued research and software enhancement.</p>"},{"location":"about/#the-alan-turing-institute","title":"The Alan Turing Institute","text":"<p>The UK's national institute for data science and artificial intelligence, provided computational expertise and infrastructure for the original Palaeoanalytics project.</p>"},{"location":"about/#university-of-cambridge","title":"University of Cambridge","text":"<p>The Leverhulme Centre for Human Evolutionary Studies (LCHES) provides archaeological expertise and access to extensive lithic collections for method development and validation throughout both phases of the project.</p>"},{"location":"about/#funding-and-support","title":"Funding and Support","text":"<p>This research is supported by:</p> <ul> <li>The British Academy</li> <li>The Alan Turing Institute</li> <li>The University of Cambridge</li> <li>The Leverhulme Centre for Human Evolutionary Studies</li> </ul> <p>We are grateful for the institutional support that has made this project possible.</p>"},{"location":"about/#citation","title":"Citation","text":"<p>If you use PyLithics in your research, please cite:</p> <p></p>"},{"location":"about/#recommended-citation-format","title":"Recommended Citation Format","text":"<pre><code>Gellis, J., Rangel Smith, C., &amp; Foley, R. (2024). PyLithics: A Python package for\narchaeological lithic analysis [Computer software].\nhttps://doi.org/10.5281/zenodo.303727518\n</code></pre>"},{"location":"about/#bibtex-entry","title":"BibTeX Entry","text":"<pre><code>@software{pylithics2024,\\n  author = {Gellis, Jason and {Rangel Smith}, Camila and Foley, Robert},\\n  title = {PyLithics: A Python package for archaeological lithic analysis},\\n  year = {2024},\\n  publisher = {Zenodo},\\n  doi = {10.5281/zenodo.303727518},\\n  url = {https://github.com/alan-turing-institute/Palaeoanalytics}\\n}\n</code></pre>"},{"location":"about/#contributing","title":"Contributing","text":"<p>We welcome contributions from the archaeological and computational communities:</p>"},{"location":"about/#how-to-contribute","title":"How to Contribute","text":"<ol> <li>Report Issues: Use our GitHub issue tracker</li> <li>Suggest Features: Propose new functionality or improvements</li> <li>Code Contributions: Submit pull requests with enhancements</li> <li>Documentation: Help improve user guides and tutorials</li> <li>Testing: Validate PyLithics with your datasets</li> </ol>"},{"location":"about/#contribution-guidelines","title":"Contribution Guidelines","text":"<p>Please see our Contributing Guidelines for detailed information on how to contribute to the project.</p>"},{"location":"about/#community","title":"Community","text":""},{"location":"about/#user-support","title":"User Support","text":"<ul> <li>Documentation: Comprehensive guides and tutorials</li> <li>GitHub Discussions: Community Q&amp;A and feature requests</li> <li>Email Support: Direct contact with the development team</li> <li>Workshops: Training sessions and conference presentations</li> </ul>"},{"location":"about/#academic-collaboration","title":"Academic Collaboration","text":"<p>We actively seek collaborations with:</p> <ul> <li>Archaeological research groups</li> <li>Computer science departments</li> <li>Digital humanities initiatives</li> <li>Museum collections and cultural heritage organizations</li> </ul>"},{"location":"about/#contact-information","title":"Contact Information","text":""},{"location":"about/#general-inquiries-and-technical-support","title":"General Inquiries and Technical Support","text":"<p>For general questions about PyLithics or the Palaeoanalytics project, please contact: - Dr. Jason Gellis: jg760@cam.ac.uk</p>"},{"location":"about/#license","title":"License","text":"<p>PyLithics is licensed under the GNU General Public License v3.0 (GPL-3.0). This ensures that:</p> <ul> <li>The software remains freely available</li> <li>Users can modify and redistribute the code</li> <li>Derivative works must also be open source</li> <li>The archaeological community benefits from continued development</li> </ul>"},{"location":"about/#acknowledgments","title":"Acknowledgments","text":"<p>We thank:</p> <ul> <li>The archaeological community for feedback and validation</li> <li>Beta testers who helped refine the software</li> <li>Contributors who have improved the codebase</li> <li>Institutions that have supported this research</li> </ul> <p>The development of PyLithics has been greatly enhanced by the collaborative spirit of the open science community.</p> <p>For the latest updates and announcements, please visit our GitHub repository or contact the development team.</p>"},{"location":"installation/","title":"Installation Guide","text":"<p>This guide will walk you through installing PyLithics on your system. PyLithics requires Python 3.7 or greater and works on macOS, Windows, and Linux.</p>"},{"location":"installation/#system-requirements","title":"System Requirements","text":"<ul> <li>Python: Version 3.7 or higher</li> <li>Operating System:</li> <li>macOS 10.14 or later</li> <li>Windows 10 or later</li> <li>Linux (Ubuntu 18.04+, CentOS 7+, or equivalent)</li> <li>Memory: Minimum 4GB RAM (8GB recommended for large datasets)</li> <li>Storage: 500MB for installation plus space for your data</li> </ul>"},{"location":"installation/#step-1-verify-prerequisites","title":"Step 1: Verify Prerequisites","text":"<p>Before installing PyLithics, ensure you have Python and Git installed on your system.</p>"},{"location":"installation/#check-python-installation","title":"Check Python Installation","text":"macOS &amp; LinuxWindows <pre><code># Check Python version (should be 3.7+)\npython3 --version\n\n# If not installed, install Python\n# macOS (using Homebrew - install from https://brew.sh/)\nbrew install python@3.7\n\n# Ubuntu/Debian\nsudo apt-get update\nsudo apt-get install python3 python3-pip python3-venv\n\n# CentOS/RHEL\nsudo yum install python3 python3-pip\n</code></pre> <pre><code># Check Python version (should be 3.7+)\npython --version\n\n# If not installed, download from https://python.org\n# Make sure to check \"Add Python to PATH\" during installation\n</code></pre>"},{"location":"installation/#check-git-installation","title":"Check Git Installation","text":"macOS &amp; LinuxWindows <pre><code># Check Git version\ngit --version\n\n# If not installed\n# macOS (using Homebrew - install from https://brew.sh/)\nbrew install git\n\n# Ubuntu/Debian\nsudo apt-get install git\n\n# CentOS/RHEL\nsudo yum install git\n</code></pre> <pre><code># Check Git version\ngit --version\n\n# If not installed, download from https://git-scm.com/\n</code></pre> <p>Python Version</p> <p>PyLithics requires Python 3.7 or higher. If you have an older version, please upgrade before proceeding.</p>"},{"location":"installation/#step-2-set-up-a-virtual-environment","title":"Step 2: Set Up a Virtual Environment","text":"<p>We strongly recommend using a virtual environment to avoid conflicts with other Python packages.</p> macOS &amp; LinuxWindows <pre><code># Create virtual environment\npython3 -m venv palaeo\n\n# Activate virtual environment\nsource palaeo/bin/activate\n</code></pre> <pre><code># Create virtual environment\npython -m venv palaeo\n\n# Allow script execution (may require administrator privileges)\nSet-ExecutionPolicy Unrestricted -Scope Process\n\n# Activate virtual environment\n.\\palaeo\\Scripts\\activate\n</code></pre> <p>Virtual Environment Active</p> <p>When your virtual environment is active, you'll see <code>(palaeo)</code> at the beginning of your command prompt.</p>"},{"location":"installation/#step-3-clone-the-repository","title":"Step 3: Clone the Repository","text":"<p>Clone the PyLithics repository from GitHub:</p> <pre><code>git clone https://github.com/alan-turing-institute/Palaeoanalytics.git\ncd Palaeoanalytics\n</code></pre>"},{"location":"installation/#choosing-a-branch","title":"Choosing a Branch","text":"<ul> <li>Stable Version: Use the <code>main</code> branch for the most stable release</li> <li>Latest Features: Use the <code>staging</code> branch for the newest features (may be less stable)</li> </ul> <pre><code># For stable version (recommended)\ngit checkout main\n\n# For latest features\ngit checkout staging\n</code></pre>"},{"location":"installation/#step-4-install-pylithics","title":"Step 4: Install PyLithics","text":"<p>Install PyLithics and all its dependencies:</p> <pre><code>pip install .\n</code></pre> <p>This command will: - Install PyLithics as a package - Install all required dependencies listed in <code>requirements.txt</code> - Set up command-line tools (<code>pylithics</code> and <code>pylithics-run</code>)</p>"},{"location":"installation/#step-5-verify-installation","title":"Step 5: Verify Installation","text":"<p>Test that PyLithics is correctly installed:</p> <pre><code># Check if PyLithics is available\npylithics --help\n\n# Or use the alternative command\npylithics-run --help\n</code></pre> <p>You should see the help text displaying available options and commands.</p>"},{"location":"installation/#updating-pylithics","title":"Updating PyLithics","text":"<p>To update to the latest version:</p> <pre><code># Navigate to PyLithics directory\ncd Palaeoanalytics\n\n# Pull latest changes\ngit pull origin main\n\n# Reinstall\npip install . --upgrade\n</code></pre>"},{"location":"installation/#building-documentation-locally","title":"Building Documentation Locally","text":"<p>Documentation tools are installed automatically with PyLithics. To build and view the documentation locally:</p> <pre><code># Serve documentation locally at http://127.0.0.1:8000\nmkdocs serve\n\n# Build static site\nmkdocs build\n</code></pre> <p>Documentation Tools Included</p> <p>MkDocs and related documentation dependencies are automatically installed with PyLithics, so no additional installation is needed.</p>"},{"location":"installation/#troubleshooting-installation","title":"Troubleshooting Installation","text":""},{"location":"installation/#python-version-issues","title":"Python Version Issues","text":"<p>If you encounter Python version errors:</p> <pre><code># Check your Python version\npython --version\n\n# If needed, install Python 3.7+ using your system's package manager\n# macOS (using Homebrew)\nbrew install python@3.9\n\n# Ubuntu/Debian\nsudo apt-get update\nsudo apt-get install python3.9\n\n# Windows - download from python.org\n</code></pre>"},{"location":"installation/#macos-specific-issues","title":"macOS-Specific Issues","text":"<p>For macOS users with OS versions below 10.14: - Consider upgrading your OS to 10.14 or later - If upgrade isn't possible, you may encounter build issues with some dependencies</p>"},{"location":"installation/#windows-powershell-execution-policy","title":"Windows PowerShell Execution Policy","text":"<p>If you get execution policy errors on Windows: <pre><code># Run PowerShell as Administrator\nSet-ExecutionPolicy RemoteSigned\n\n# Or for current session only\nSet-ExecutionPolicy Unrestricted -Scope Process\n</code></pre></p>"},{"location":"installation/#missing-dependencies","title":"Missing Dependencies","text":"<p>If you encounter missing dependency errors: <pre><code># Upgrade pip first\npip install --upgrade pip\n\n# Then reinstall with verbose output\npip install . -v\n</code></pre></p>"},{"location":"installation/#opencv-installation-issues","title":"OpenCV Installation Issues","text":"<p>If OpenCV fails to install: <pre><code># Try installing OpenCV separately first\npip install opencv-python-headless&gt;=4.8.0\n\n# Then install PyLithics\npip install .\n</code></pre></p>"},{"location":"installation/#uninstalling","title":"Uninstalling","text":"<p>To remove PyLithics:</p> <pre><code># Uninstall PyLithics\npip uninstall pylithics\n\n# Deactivate and remove virtual environment\ndeactivate\nrm -rf palaeo/  # On Windows: rmdir /s palaeo\n</code></pre>"},{"location":"installation/#next-steps","title":"Next Steps","text":"<p>Now that PyLithics is installed, you're ready to:</p> <ol> <li>Prepare your images</li> <li>Set up metadata</li> <li>Run your first analysis</li> </ol> <p>For any installation issues not covered here, please check our troubleshooting guide or open an issue on GitHub.</p>"},{"location":"reference/cli-commands/","title":"CLI Commands Reference","text":""},{"location":"reference/cli-commands/#command-overview","title":"Command Overview","text":"<p>PyLithics is run using Python directly:</p> <pre><code>python pylithics/app.py [options]\n</code></pre>"},{"location":"reference/cli-commands/#required-arguments","title":"Required Arguments","text":"<p>Every PyLithics run requires these two arguments:</p> Argument Description Example <code>--data_dir</code> Directory containing images/ and scales/ subdirectories <code>pylithics/data</code> <code>--meta_file</code> Path to metadata CSV file <code>pylithics/data/meta_data.csv</code>"},{"location":"reference/cli-commands/#basic-usage","title":"Basic Usage","text":"<pre><code>python pylithics/app.py --data_dir pylithics/data --meta_file pylithics/data/meta_data.csv\n</code></pre>"},{"location":"reference/cli-commands/#configuration-options","title":"Configuration Options","text":""},{"location":"reference/cli-commands/#configuration-hierarchy","title":"Configuration Hierarchy","text":"<p>PyLithics uses a three-layer configuration system:</p> <ol> <li>Default settings - Built into the code</li> <li>YAML configuration - From config.yaml file</li> <li>CLI overrides - Command-line arguments (highest priority)</li> </ol>"},{"location":"reference/cli-commands/#using-a-configuration-file","title":"Using a Configuration File","text":"Option Description Default <code>--config_file</code> Path to YAML configuration file None (uses defaults) <pre><code>python pylithics/app.py --data_dir pylithics/data --meta_file pylithics/data/meta_data.csv \\\n         --config_file ./my_config.yaml\n</code></pre>"},{"location":"reference/cli-commands/#example-configuration-file","title":"Example Configuration File","text":"<pre><code># config.yaml\nthresholding:\n  method: otsu              # simple, otsu, or adaptive\n  threshold_value: 127      # For simple method\n  max_value: 255\n\nscale_calibration:\n  enabled: true             # Enable scale bar detection\n  debug_output: false       # Save detection debug images\n\narrow_detection:\n  enabled: true\n  reference_dpi: 300.0\n  min_area_scale_factor: 0.7\n  max_area_scale_factor: 10.0\n  min_aspect_ratio: 1.5\n  debug_enabled: false\n\nsurface_classification:\n  enabled: true\n  classification_rules:\n    dorsal_area_threshold: 0.6\n    ventral_area_threshold: 0.4\n\nscar_complexity:\n  enabled: true\n  distance_threshold: 10.0\n\ncortex_detection:\n  enabled: true\n  min_area: 100\n  detection_method: color_threshold\n\nsymmetry_analysis:\n  enabled: true\n  axis: both              # vertical, horizontal, or both\n\nvoronoi_analysis:\n  enabled: true\n  output_diagrams: true\n\nlateral_analysis:\n  enabled: true\n  convexity_threshold: 0.8\n\nlogging:\n  level: INFO            # DEBUG, INFO, WARNING, ERROR\n  log_to_file: true\n  log_file: pylithics.log\n</code></pre>"},{"location":"reference/cli-commands/#common-usage-patterns","title":"Common Usage Patterns","text":""},{"location":"reference/cli-commands/#basic-analysis","title":"Basic Analysis","text":"<pre><code># Simple processing with default settings\npython pylithics/app.py --data_dir pylithics/data --meta_file pylithics/data/meta_data.csv\n</code></pre>"},{"location":"reference/cli-commands/#with-arrow-detection","title":"With Arrow Detection","text":"<pre><code># Enable arrow detection for flaking direction\npython pylithics/app.py --data_dir pylithics/data --meta_file pylithics/data/meta_data.csv \\\n         --arrow_debug\n</code></pre>"},{"location":"reference/cli-commands/#debug-mode","title":"Debug Mode","text":"<pre><code># Verbose output for troubleshooting\npython pylithics/app.py --data_dir pylithics/data --meta_file pylithics/data/meta_data.csv \\\n         --log_level DEBUG\n</code></pre>"},{"location":"reference/cli-commands/#dpi-aware-processing","title":"DPI-Aware Processing","text":"<pre><code># Default: Fixed kernels optimized for archaeological line drawings (recommended)\npython pylithics/app.py --data_dir pylithics/data --meta_file pylithics/data/meta_data.csv\n\n# Enable DPI-aware scaling for noisy photographs or degraded scans\npython pylithics/app.py --data_dir pylithics/data --meta_file pylithics/data/meta_data.csv \\\n         --enable_dpi_scaling\n\n# DPI scaling with conservative mode (minimal scaling)\npython pylithics/app.py --data_dir pylithics/data --meta_file pylithics/data/meta_data.csv \\\n         --enable_dpi_scaling --dpi_scaling_mode conservative\n\n# DPI scaling with aggressive mode (maximum noise removal)\npython pylithics/app.py --data_dir pylithics/data --meta_file pylithics/data/meta_data.csv \\\n         --enable_dpi_scaling --dpi_scaling_mode aggressive\n\n# Custom DPI settings\npython pylithics/app.py --data_dir pylithics/data --meta_file pylithics/data/meta_data.csv \\\n         --enable_dpi_scaling --dpi_reference 150 --dpi_max_scale 2.0\n</code></pre>"},{"location":"reference/cli-commands/#fast-processing","title":"Fast Processing","text":"<pre><code># Disable time-consuming features for speed\npython pylithics/app.py --data_dir pylithics/data --meta_file pylithics/data/meta_data.csv \\\n         --disable_arrow_detection \\\n         --disable_voronoi\n</code></pre>"},{"location":"reference/cli-commands/#custom-thresholding","title":"Custom Thresholding","text":"<pre><code># Use adaptive thresholding for poor contrast\npython pylithics/app.py --data_dir pylithics/data --meta_file pylithics/data/meta_data.csv \\\n         --threshold_method adaptive\n</code></pre>"},{"location":"reference/cli-commands/#thresholding-options","title":"Thresholding Options","text":"Option Values Description Default <code>--threshold_method</code> <code>simple</code>, <code>otsu</code>, <code>adaptive</code> Image binarization method <code>simple</code> <code>--threshold_value</code> 0-255 Threshold for simple method 127 <code>--max_value</code> 0-255 Maximum value after thresholding 255 <pre><code># Use Otsu automatic thresholding\npython pylithics/app.py --data_dir pylithics/data --meta_file pylithics/data/meta_data.csv \\\n         --threshold_method otsu\n\n# Use adaptive thresholding for poor contrast\npython pylithics/app.py --data_dir pylithics/data --meta_file pylithics/data/meta_data.csv \\\n         --threshold_method adaptive\n\n# Manual threshold adjustment\npython pylithics/app.py --data_dir pylithics/data --meta_file pylithics/data/meta_data.csv \\\n         --threshold_method simple --threshold_value 100\n</code></pre>"},{"location":"reference/cli-commands/#feature-control","title":"Feature Control","text":""},{"location":"reference/cli-commands/#enablingdisabling-analysis-modules","title":"Enabling/Disabling Analysis Modules","text":"Feature Enable Disable Default Scale Calibration Default enabled <code>--disable_scale_calibration</code> Enabled Arrow Detection Default enabled <code>--disable_arrow_detection</code> Enabled Voronoi Analysis Default enabled <code>--disable_voronoi</code> Enabled Symmetry Analysis Default enabled <code>--disable_symmetry</code> Enabled Scar Complexity Default enabled <code>--disable_scar_complexity</code> Enabled Cortex Detection <code>--enable_cortex_detection</code> Default disabled Disabled Lateral Analysis Default enabled <code>--disable_lateral</code> Enabled"},{"location":"reference/cli-commands/#scale-calibration-options","title":"Scale Calibration Options","text":"Option Description Default <code>--disable_scale_calibration</code> Skip scale bar detection entirely False <code>--scale_debug</code> Save scale detection debug images False <code>--force_scale_method</code> Force specific calibration method: <code>scale_bar</code>, <code>pixels</code> None <pre><code># Enable scale debugging\npylithics --data_dir ./data --meta_file ./meta.csv --scale_debug\n\n# Force pixel measurements only\npylithics --data_dir ./data --meta_file ./meta.csv --force_scale_method pixels\n\n# Disable scale calibration (pixel measurements only)\npylithics --data_dir ./data --meta_file ./meta.csv --disable_scale_calibration\n</code></pre>"},{"location":"reference/cli-commands/#dpi-processing-options","title":"DPI Processing Options","text":"<p>PyLithics automatically detects image DPI and processes accordingly. By default, it uses fixed kernel sizes optimized for archaeological line drawings (75-600 DPI range).</p> Option Description Default <code>--enable_dpi_scaling</code> Enable DPI-aware kernel scaling False (fixed kernels) <code>--dpi_scaling_mode</code> Scaling strategy: <code>conservative</code>, <code>standard</code>, <code>aggressive</code> <code>standard</code> <code>--dpi_reference</code> Reference DPI for scaling calculations 300.0 <code>--dpi_max_scale</code> Maximum scaling factor limit 1.5 <p>Scaling Modes:</p> <ul> <li>Conservative: Minimal scaling, preserves fine line details</li> <li>Standard: Moderate linear scaling with caps (default when DPI scaling enabled)</li> <li>Aggressive: Full proportional scaling, maximum noise removal</li> </ul> <pre><code># Default: Fixed kernels (recommended for archaeological line drawings)\npylithics --data_dir ./data --meta_file ./meta.csv\n\n# Enable DPI scaling for noisy photographs\npylithics --data_dir ./data --meta_file ./meta.csv --enable_dpi_scaling\n\n# Conservative scaling (minimal)\npylithics --data_dir ./data --meta_file ./meta.csv --enable_dpi_scaling --dpi_scaling_mode conservative\n\n# Aggressive scaling (maximum noise removal)\npylithics --data_dir ./data --meta_file ./meta.csv --enable_dpi_scaling --dpi_scaling_mode aggressive\n\n# Custom DPI settings\npylithics --data_dir ./data --meta_file ./meta.csv --enable_dpi_scaling \\\n         --dpi_reference 150 --dpi_max_scale 2.0\n</code></pre> <p>When to Use DPI Scaling:</p> <ul> <li>\u2705 Enable for: Noisy photographs, degraded scans, mixed-quality datasets</li> <li>\u274c Disable for: Clean archaeological line drawings, consistent quality scans</li> </ul>"},{"location":"reference/cli-commands/#arrow-detection-options","title":"Arrow Detection Options","text":"Option Description Default <code>--disable_arrow_detection</code> Skip arrow detection entirely False <code>--arrow_debug</code> Save arrow detection debug images False <code>--show_arrow_lines</code> Draw red arrow lines on output False <code>--arrow_reference_dpi</code> Reference DPI for scaling 300.0 <p>```bash\\n# Enable arrow debugging\\npylithics --data_dir ./data --meta_file ./meta.csv --arrow_debug\\n\\n# Disable arrow detection for speed\\npylithics --data_dir ./data --meta_file ./meta.csv --disable_arrow_detection\\n\\n# Show arrow direction lines\\npylithics --data_dir ./data --meta_file ./meta.csv --show_arrow_lines <pre><code>### Scar Complexity Options\n\n| Option | Description | Default |\n|--------|-------------|---------|\n| `--scar_complexity_distance_threshold` | Adjacency detection distance (pixels) | 10.0 |\n| `--disable_scar_complexity` | Skip scar adjacency analysis | False |\n\n```bash\\n# Adjust adjacency sensitivity\\npylithics --data_dir ./data --meta_file ./meta.csv \\\\\\n         --scar_complexity_distance_threshold 15.0\n</code></pre></p>"},{"location":"reference/cli-commands/#cortex-detection-options","title":"Cortex Detection Options","text":"Option Description Default <code>--enable_cortex_detection</code> Enable cortex area detection False <code>--cortex_method</code> Detection method: <code>color</code>, <code>texture</code>, <code>pattern</code> <code>color</code> <code>--cortex_threshold</code> Detection sensitivity 0.5 <p>```bash\\n# Enable cortex detection\\npylithics --data_dir ./data --meta_file ./meta.csv --enable_cortex_detection <pre><code>## Output Options\n\n### Output Format\n\n| Option | Values | Description | Default |\n|--------|--------|-------------|---------|\n| `--output_format` | `csv`, `json` | Data output format | `csv` |\n| `--output_dir` | Directory path | Custom output location | `./processed` |\n\n```bash\\n# JSON output\\npylithics --data_dir ./data --meta_file ./meta.csv --output_format json\\n\\n# Custom output directory\\npylithics --data_dir ./data --meta_file ./meta.csv --output_dir ./results\n</code></pre></p>"},{"location":"reference/cli-commands/#visualization-options","title":"Visualization Options","text":"Option Description Default <code>--save_visualizations</code> Save all visualization outputs True <code>--no_images</code> Skip image output generation False <code>--show_thresholded_images</code> Display thresholding results False <p>```bash\\n# Data only, no images\\npylithics --data_dir ./data --meta_file ./meta.csv --no_images\\n\\n# Show intermediate processing steps\\npylithics --data_dir ./data --meta_file ./meta.csv --show_thresholded_images <pre><code>## Preprocessing Options\n\n### Image Enhancement\n\n| Option | Description | Default |\n|--------|-------------|---------|\n| `--closing` | Apply morphological closing | True |\n| `--closing_kernel_size` | Closing operation kernel size | 3 |\n| `--denoise` | Apply noise reduction | False |\n| `--contrast_stretch` | Enhance image contrast | False |\n\n```bash\\n# Disable morphological closing\\npylithics --data_dir ./data --meta_file ./meta.csv --no_closing\\n\\n# Enable denoising for noisy scans\\npylithics --data_dir ./data --meta_file ./meta.csv --denoise\n</code></pre></p>"},{"location":"reference/cli-commands/#logging-and-debug-options","title":"Logging and Debug Options","text":""},{"location":"reference/cli-commands/#logging-control","title":"Logging Control","text":"Option Values Description Default <code>--log_level</code> <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code> Logging verbosity <code>INFO</code> <code>--log_file</code> File path Custom log file location <code>./processed/pylithics.log</code> <code>--quiet</code> - Suppress console output False <p>```bash\\n# Debug mode with verbose output\\npylithics --data_dir ./data --meta_file ./meta.csv --log_level DEBUG\\n\\n# Quiet mode\\npylithics --data_dir ./data --meta_file ./meta.csv --quiet\\n\\n# Custom log file\\npylithics --data_dir ./data --meta_file ./meta.csv --log_file ./my_analysis.log <pre><code>### Debug Options\n\n| Option | Description | Output Location |\n|--------|-------------|-----------------|\n| `--arrow_debug` | Arrow detection debug images | `processed/arrow_debug/` |\n| `--contour_debug` | Contour detection debug images | `processed/contour_debug/` |\n| `--show_thresholded_images` | Display threshold results | Console |\n| `--save_intermediate` | Save all intermediate processing steps | `processed/intermediate/` |\n\n```bash\\n# Full debug mode\\npylithics --data_dir ./data --meta_file ./meta.csv \\\\\\n         --log_level DEBUG \\\\\\n         --arrow_debug \\\\\\n         --contour_debug \\\\\\n         --save_intermediate\n</code></pre></p>"},{"location":"reference/cli-commands/#performance-options","title":"Performance Options","text":""},{"location":"reference/cli-commands/#speed-optimization","title":"Speed Optimization","text":"<p>```bash\\n# Fastest processing (minimal features)\\npylithics --data_dir ./data --meta_file ./meta.csv \\\\n         --disable_arrow_detection \\\\n         --disable_voronoi \\\\n         --disable_symmetry \\\\n         --disable_scar_complexity \\\\n         --threshold_method simple \\\\n         --no_images\\n\\n# Balanced speed/features\\npylithics --data_dir ./data --meta_file ./meta.csv \\\\n         --disable_arrow_detection \\\\n         --threshold_method otsu <pre><code>### Memory Management\n\n| Option | Description |\n|--------|-------------|\n| `--batch_size` | Process images in batches |\n| `--max_image_size` | Resize large images |\n| `--cleanup_temp` | Remove temporary files |\n\n```bash\\n# Memory-efficient processing\\npylithics --data_dir ./large_dataset --meta_file ./meta.csv \\\\\\n         --batch_size 10 \\\\\\n         --max_image_size 2048 \\\\\\n         --cleanup_temp\n</code></pre></p>"},{"location":"reference/cli-commands/#configuration-file-override","title":"Configuration File Override","text":""},{"location":"reference/cli-commands/#cli-override-pattern","title":"CLI Override Pattern","text":"<p>Command-line arguments override configuration file settings using dot notation:</p> <p>```bash\\n# Override arrow detection settings\\npylithics --data_dir ./data --meta_file ./meta.csv \\\\n         --config_file ./config.yaml \\\\n         --arrow_reference_dpi 600 \\\\n         --disable_arrow_detection\\n\\n# Override thresholding settings\\npylithics --data_dir ./data --meta_file ./meta.csv \\\\n         --config_file ./config.yaml \\\\n         --threshold_method adaptive \\\\n         --threshold_value 120 <pre><code>### Complete Configuration Example\n\n```yaml\\n# config.yaml - Complete configuration template\\nthresholding:\\n  method: otsu\\n  threshold_value: 127\\n  max_value: 255\\n  adaptive_block_size: 11\\n  adaptive_constant: 2\\n\\nscale_calibration:\\n  enabled: true\\n  debug_output: false\\n\\narrow_detection:\\n  enabled: true\\n  reference_dpi: 300.0\\n  min_area_scale_factor: 0.7\\n  max_area_scale_factor: 10.0\\n  min_aspect_ratio: 1.5\\n  debug_enabled: false\\n\\nsurface_classification:\\n  enabled: true\\n  classification_rules:\\n    dorsal_area_threshold: 0.6\\n    ventral_area_threshold: 0.4\\n    platform_area_threshold: 0.1\\n\\nscar_complexity:\\n  enabled: true\\n  distance_threshold: 10.0\\n  min_scar_area: 50\\n\\ncortex_detection:\\n  enabled: false\\n  method: color_threshold\\n  threshold: 0.5\\n  min_area: 100\\n\\nsymmetry_analysis:\\n  enabled: true\\n  axis: both\\n  tolerance: 0.1\\n\\nvoronoi_analysis:\\n  enabled: true\\n  min_scars: 3\\n  output_diagrams: true\\n  boundary_method: convex\\n\\nlateral_analysis:\\n  enabled: true\\n  convexity_threshold: 0.8\\n  edge_sensitivity: 0.5\\n\\npreprocessing:\\n  denoise: false\\n  morphological_closing: true\\n  closing_kernel_size: 3\\n  contrast_stretch: false\\n\\nlogging:\\n  level: INFO\\n  log_to_file: true\\n  log_file: pylithics.log\\n\\noutput:\\n  format: csv\\n  save_visualizations: true\\n  save_intermediate: false\\n```\n\n## Help Commands\n\n### Built-in Help\n\n| Command | Description |\n|---------|-------------|\n| `--help`, `-h` | Show all available options |\n| `--help-config` | Show configuration file options |\n| `--help-examples` | Show usage examples |\n| `--help-troubleshooting` | Show common issues and fixes |\n| `--version` | Show PyLithics version |\n\n```bash\\n# Get help\\npylithics --help\\n\\n# Configuration help\\npylithics --help-config\\n\\n# Example commands\\npylithics --help-examples\\n\\n# Troubleshooting guide\\npylithics --help-troubleshooting\n</code></pre></p>"},{"location":"reference/cli-commands/#common-command-patterns","title":"Common Command Patterns","text":""},{"location":"reference/cli-commands/#development-and-testing","title":"Development and Testing","text":"<p>```bash\\n# Quick test with sample data\\npylithics --data_dir ./pylithics/data --meta_file ./pylithics/data/meta_data.csv\\n\\n# Test single image\\npylithics --data_dir ./test_single --meta_file ./single_meta.csv --log_level DEBUG\\n\\n# Validation run with all debug output\\npylithics --data_dir ./validation --meta_file ./val_meta.csv \\\\n         --log_level DEBUG \\\\n         --arrow_debug \\\\n         --save_intermediate <pre><code>### Production Analysis\n\n```bash\\n# Standard archaeological analysis\\npylithics --data_dir ./assemblage --meta_file ./metadata.csv \\\\\\n         --config_file ./site_config.yaml \\\\\\n         --log_level INFO\\n\\n# Publication-quality analysis\\npylithics --data_dir ./publication_data --meta_file ./pub_meta.csv \\\\\\n         --arrow_debug \\\\\\n         --save_visualizations \\\\\\n         --output_format csv\\n\\n# Batch processing multiple sites\\nfor site in site_*; do\\n    pylithics --data_dir ./$site --meta_file ./$site/metadata.csv \\\\\\n             --output_dir ./results/$site\\ndone\n</code></pre></p>"},{"location":"reference/cli-commands/#performance-optimized","title":"Performance-Optimized","text":"<p>```bash\\n# Large dataset processing\\npylithics --data_dir ./large_assemblage --meta_file ./large_meta.csv \\\\n         --disable_arrow_detection \\\\n         --disable_voronoi \\\\n         --threshold_method simple \\\\n         --no_images \\\\n         --quiet\\n\\n# Memory-constrained environment\\npylithics --data_dir ./data --meta_file ./meta.csv \\\\n         --batch_size 5 \\\\n         --max_image_size 1024 \\\\n         --cleanup_temp <pre><code>## Exit Codes\n\n| Code | Meaning |\n|------|---------|\n| 0 | Successful completion |\n| 1 | General error |\n| 2 | Invalid arguments |\n| 3 | File not found |\n| 4 | Configuration error |\n| 5 | Processing error |\n\n## Environment Variables\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| `PYLITHICS_CONFIG` | Default config file path | None |\n| `PYLITHICS_DATA_DIR` | Default data directory | None |\n| `PYLITHICS_LOG_LEVEL` | Default log level | INFO |\n\n```bash\\n# Set environment variables\\nexport PYLITHICS_CONFIG=./default_config.yaml\\nexport PYLITHICS_LOG_LEVEL=DEBUG\\n\\n# Then run with simplified command\\npylithics --data_dir ./data --meta_file ./meta.csv\n</code></pre></p>"},{"location":"user-guide/","title":"User Guide","text":""},{"location":"user-guide/#welcome-to-the-pylithics-user-guide","title":"Welcome to the PyLithics User Guide","text":"<p>This comprehensive guide provides step-by-step instructions and best practices to help you get the most out of PyLithics for your lithic analysis.</p>"},{"location":"user-guide/#guide-contents","title":"Guide Contents","text":""},{"location":"user-guide/#image-requirements","title":"Image Requirements","text":"<p>Learn about the image specifications and drawing conventions that work best with PyLithics:</p> <ul> <li>Supported file formats and resolutions</li> <li>Drawing style guidelines</li> <li>Orientation requirements</li> <li>Scale bar placement</li> <li>Tips for optimal results</li> </ul>"},{"location":"user-guide/#metadata-setup","title":"Metadata Setup","text":"<p>Understand how to prepare your metadata CSV file and scale calibration:</p> <ul> <li>Required columns and format</li> <li>Automatic scale bar detection system</li> <li>Automatic fallback to pixel measurements</li> <li>Linking images to scales</li> <li>Directory structure organization</li> <li>Handling missing scales and mixed calibration methods</li> <li>Example templates</li> </ul>"},{"location":"user-guide/#basic-usage","title":"Basic Usage","text":"<p>Get started with running PyLithics analyses:</p> <ul> <li>Command-line basics</li> <li>Essential arguments</li> <li>Scale calibration examples and options</li> <li>Configuration options (config.yaml)</li> <li>Understanding the processing pipeline</li> <li>Customizing analysis parameters</li> </ul>"},{"location":"user-guide/#outputs","title":"Outputs","text":"<p>Explore all the files and data PyLithics generates:</p> <ul> <li>CSV data structure and metrics</li> <li>Scale calibration metadata columns</li> <li>Labeled visualization images</li> <li>Voronoi diagrams</li> <li>Log files and debugging output</li> <li>Arrow detection results</li> </ul>"},{"location":"user-guide/#voronoi-analysis-convex-hull","title":"Voronoi Analysis &amp; Convex Hull","text":"<p>PyLithics built-in spatial analysis features:</p> <ul> <li>Understanding Voronoi diagrams</li> <li>Convex hull calculations</li> <li>Configuration options</li> <li>Archaeological applications</li> </ul>"},{"location":"user-guide/#lithic-editor","title":"Lithic Editor","text":"<p>Coming Soon - Manual editing and correction tools:</p> <ul> <li>Planned features</li> <li>Integration with PyLithics workflow</li> <li>Future development roadmap</li> </ul>"},{"location":"user-guide/#troubleshooting","title":"Troubleshooting","text":"<p>Solve common issues and optimize performance:</p> <ul> <li>Error messages and solutions</li> <li>Image preprocessing problems</li> <li>Configuration troubleshooting</li> <li>Performance optimization tips</li> <li>Disabling features for speed</li> </ul>"},{"location":"user-guide/#glossary","title":"Glossary","text":"<p>Reference for all terms and metrics:</p> <ul> <li>Complete list of measurements</li> <li>Archaeological terminology</li> <li>Technical definitions</li> <li>Metric units and calculations</li> </ul>"},{"location":"user-guide/#next-steps","title":"Next Steps","text":"<ol> <li>Start here \u2192 Image Requirements - Ensure your images are compatible</li> <li>Next \u2192 Metadata Setup - Prepare your CSV file</li> <li>Then \u2192 Basic Usage - Run your first analysis</li> <li>Finally \u2192 Outputs - Understand your results</li> </ol>"},{"location":"user-guide/basic-usage/","title":"Basic Usage","text":""},{"location":"user-guide/basic-usage/#command-line-basics","title":"Command Line Basics","text":""},{"location":"user-guide/basic-usage/#required-arguments","title":"Required Arguments","text":"<p>Every PyLithics run requires these two arguments:</p> Argument Description Example <code>--data_dir</code> Directory containing images and scales <code>pylithics/data</code> <code>--meta_file</code> Path to metadata CSV file <code>pylithics/data/meta_data.csv</code>"},{"location":"user-guide/basic-usage/#basic-command-structure","title":"Basic Command Structure","text":"<p>Run PyLithics 'out of the box' with minimal configuration:</p> <p><pre><code>python pylithics/app.py --data_dir pylithics/data --meta_file pylithics/data/meta_data.csv\n</code></pre> This command will:</p> <ol> <li>Load images from <code>pylithics/data/images/</code></li> <li>Load scales from <code>pylithics/data/scales/</code></li> <li>Process according to default settings</li> <li>Output results to <code>pylithics/data/processed/</code></li> </ol> <p>Choose your own paths for image and metadata directories:</p> <pre><code>python pylithics/app.py --data_dir &lt;path&gt; --meta_file &lt;file&gt; [options]\n</code></pre>"},{"location":"user-guide/basic-usage/#scale-calibration-examples","title":"Scale Calibration Examples","text":"<pre><code># Basic analysis with automatic scale detection\npython pylithics/app.py --data_dir ./data --meta_file ./metadata.csv\n\n# Force pixel measurements only (skip scale bar detection)\npython pylithics/app.py --data_dir ./data --meta_file ./metadata.csv --force_scale_method pixels\n\n# Enable scale detection debugging\npython pylithics/app.py --data_dir ./data --meta_file ./metadata.csv --scale_debug\n\n# Process without any calibration (pixel measurements only)\npython pylithics/app.py --data_dir ./data --meta_file ./metadata.csv --disable_scale_calibration\n</code></pre>"},{"location":"user-guide/basic-usage/#dpi-processing-examples","title":"DPI Processing Examples","text":"<pre><code># Default processing (recommended for archaeological line drawings)\n# Uses fixed kernels optimized for 75-600 DPI range\npython pylithics/app.py --data_dir ./data --meta_file ./metadata.csv\n\n# Enable DPI-aware scaling for noisy photographs or degraded scans\npython pylithics/app.py --data_dir ./data --meta_file ./metadata.csv --enable_dpi_scaling\n\n# DPI scaling with conservative mode (minimal scaling)\npython pylithics/app.py --data_dir ./data --meta_file ./metadata.csv --enable_dpi_scaling --dpi_scaling_mode conservative\n\n# DPI scaling with aggressive mode (maximum noise removal)\npython pylithics/app.py --data_dir ./data --meta_file ./metadata.csv --enable_dpi_scaling --dpi_scaling_mode aggressive\n\n# Custom DPI parameters\npython pylithics/app.py --data_dir ./data --meta_file ./metadata.csv --enable_dpi_scaling --dpi_reference 150 --dpi_max_scale 2.0\n</code></pre>"},{"location":"user-guide/basic-usage/#understanding-the-pylithics-pipeline","title":"Understanding the PyLithics Pipeline","text":""},{"location":"user-guide/basic-usage/#processing-flow","title":"Processing Flow","text":"<pre><code>%%{init: {'theme':'base', 'themeVariables': {'primaryColor': '#ffffff', 'primaryTextColor': '#000000', 'primaryBorderColor': '#000000', 'lineColor': '#000000', 'fontSize': '12px'}}}%%\nflowchart TD\n    A[Import and validate images] --&gt; B[Convert pixels to millimeters]\n    B --&gt; C[Noise removal and&lt;br/&gt;contrast enhancement]\n    C --&gt; D[Image Thresholding]\n    D --&gt; E[Contour Extraction]\n    E --&gt; F[Surface Classification]\n    F --&gt; G[Calculate metrics]\n    G --&gt; H{Arrow Detection}\n    H --&gt;|Yes| I[Calculate directions]\n    H --&gt;|No| J[Voronoi Analysis&lt;br/&gt; &amp; Convex Hull]\n    I --&gt; J[Voronoi Analysis&lt;br/&gt; &amp; Convex Hull]\n    J --&gt; K[Export CSV and images]\n\n    style A fill:#e1f5fe\n    style H fill:#fff3e0</code></pre>"},{"location":"user-guide/basic-usage/#step-descriptions","title":"Step Descriptions","text":"<p>A. Import and validate images Load lithic illustrations and verify file formats, resolution requirements</p> <p>B. Scale Calibration &amp; Conversion Automatically detect scale bars in images and calculate pixels-per-millimeter conversion factors. Uses pixel measurements if no scale calibration available.</p> <p>C. Noise removal and contrast enhancement Clean up scan artifacts and improve line definition</p> <p>D. Image Thresholding Convert to binary (black/white) using simple, Otsu, or adaptive methods</p> <p>E. Contour Extraction Find object boundaries with parent-child hierarchy (surfaces and scars)</p> <p>F. Surface Classification Identify dorsal, ventral, platform, and lateral surfaces by size and position</p> <p>G. Calculate metrics Measure dimensions, areas, aspect ratios, and shape properties</p> <p>H. Arrow Detection (Optional) Find directional force indicators using resolution-aware computer vision</p> <p>I. Calculate directions Determine flaking angles and associate arrows with specific scars</p> <p>J. Voronoi Analysis &amp; Convex Hull Generate spatial distribution patterns and calculate convex properties</p> <p>K. Export CSV and images Save measurements data and labeled visualization images</p>"},{"location":"user-guide/basic-usage/#configuration-options","title":"Configuration Options","text":""},{"location":"user-guide/basic-usage/#configuration-hierarchy","title":"Configuration Hierarchy","text":"<p>PyLithics uses a three-layer configuration system:</p> <ol> <li>Default settings - Built into the code</li> <li>YAML configuration - From config.yaml file</li> <li>CLI overrides - Command-line arguments (highest priority)</li> </ol> <p>For detailed configuration options, see the CLI Commands Reference.</p>"},{"location":"user-guide/basic-usage/#next-steps","title":"Next Steps","text":"<ul> <li>Understanding outputs - Interpret your results</li> <li>CLI Commands Reference - Complete command list</li> <li>Voronoi analysis - Spatial pattern analysis</li> <li>Troubleshooting - Solve common problems</li> </ul>"},{"location":"user-guide/glossary/","title":"Glossary","text":""},{"location":"user-guide/glossary/#metric-definitions","title":"Metric Definitions","text":"<p>This comprehensive glossary defines all measurements and terms used in PyLithics output data.</p>"},{"location":"user-guide/glossary/#basic-measurements","title":"Basic Measurements","text":""},{"location":"user-guide/glossary/#linear-dimensions","title":"Linear Dimensions","text":"technical_length (mm) Distance from the platform to the distal end, measured along the central axis perpendicular to the striking platform technical_width (mm) Maximum width measured perpendicular to the technical length axis max_length (mm) Longest dimension of the artifact regardless of orientation max_width (mm) Maximum width measured perpendicular to the maximum length thickness (mm) Maximum distance between dorsal and ventral surfaces perimeter (mm) Total length of the contour boundary"},{"location":"user-guide/glossary/#area-measurements","title":"Area Measurements","text":"area (mm\u00b2) Surface area enclosed by the contour boundary convex_hull_area (mm\u00b2) Area of the smallest convex shape that contains all points of the contour bounding_box_area (mm\u00b2) Area of the smallest rectangle that contains the entire contour"},{"location":"user-guide/glossary/#shape-properties","title":"Shape Properties","text":""},{"location":"user-guide/glossary/#ratios-and-indices","title":"Ratios and Indices","text":"aspect_ratio Ratio of technical length to technical width (length/width) circularity Shape compactness measure: 4\u03c0 \u00d7 area / perimeter\u00b2. Values near 1.0 indicate circular shapes convexity Ratio of convex hull perimeter to actual perimeter. Values near 1.0 indicate convex shapes solidity Ratio of contour area to convex hull area. Measures how \"solid\" the shape is rectangularity Ratio of contour area to bounding box area. Measures how rectangular the shape is"},{"location":"user-guide/glossary/#geometric-properties","title":"Geometric Properties","text":"centroid_x, centroid_y (mm) Coordinates of the geometric center of the contour moment_hu_1 through moment_hu_7 Hu moments - shape descriptors invariant to translation, rotation, and scaling orientation (degrees) Angle of the major axis relative to horizontal (0-180\u00b0) eccentricity Measure of shape elongation (0 = circle, 1 = line)"},{"location":"user-guide/glossary/#surface-classification","title":"Surface Classification","text":""},{"location":"user-guide/glossary/#surface-types","title":"Surface Types","text":"Dorsal Upper surface of the flake showing previous removal scars Ventral Lower surface formed during flake detachment, typically smooth Platform Prepared surface where the flake was struck from the core Lateral Side edges of the flake Unknown Surface type could not be determined automatically"},{"location":"user-guide/glossary/#feature-types","title":"Feature Types","text":"Surface Main surface contour (parent contour) Scar Individual flake removal visible on dorsal surface (child contour) Cortex Original outer surface of the raw material Retouch Intentional secondary modification of edges Platform_mark Features on the striking platform"},{"location":"user-guide/glossary/#advanced-analysis-metrics","title":"Advanced Analysis Metrics","text":""},{"location":"user-guide/glossary/#symmetry-analysis","title":"Symmetry Analysis","text":"symmetry_vertical (0-1) Measure of bilateral symmetry around vertical axis. 1.0 = perfect symmetry symmetry_horizontal (0-1) Measure of symmetry around horizontal axis. 1.0 = perfect symmetry symmetry_axis_angle (degrees) Angle of the best-fit symmetry axis symmetry_score (0-1) Overall symmetry measure combining vertical and horizontal"},{"location":"user-guide/glossary/#scar-complexity","title":"Scar Complexity","text":"scar_count Number of individual scars detected on the surface scar_complexity Number of adjacent scar relationships (scars sharing boundaries) scar_density (scars/mm\u00b2) Number of scars per unit surface area isolation_index (0-1) Measure of how isolated individual scars are from others adjacent_scars List of scar IDs that share boundaries with this scar"},{"location":"user-guide/glossary/#arrow-detection","title":"Arrow Detection","text":"has_arrow (true/false) Whether a directional arrow was detected for this scar arrow_angle (degrees) Direction of force application indicated by arrow (0-360\u00b0) arrow_length (mm) Length of the detected arrow indicator arrow_confidence (0-1) Confidence score for arrow detection force_direction (degrees) Inferred direction of knapping force"},{"location":"user-guide/glossary/#voronoi-analysis","title":"Voronoi Analysis","text":"voronoi_cells Number of Voronoi cells in the tessellation voronoi_area_mean (mm\u00b2) Average area of Voronoi cells voronoi_area_std (mm\u00b2) Standard deviation of Voronoi cell areas voronoi_density (cells/mm\u00b2) Spatial density of Voronoi cells spatial_distribution (0-1) Regularity index of spatial distribution (1.0 = perfectly regular) nearest_neighbor_distance (mm) Average distance to nearest neighboring scar"},{"location":"user-guide/glossary/#lateral-analysis","title":"Lateral Analysis","text":"lateral_convexity (0-1) Measure of edge convexity (1.0 = perfectly convex) edge_angle (degrees) Angle between dorsal and ventral surfaces at the edge edge_length (mm) Length of the lateral edge use_wear_index (0-1) Estimated use-wear based on edge characteristics"},{"location":"user-guide/glossary/#technical-terms","title":"Technical Terms","text":""},{"location":"user-guide/glossary/#image-processing","title":"Image Processing","text":"DPI (dots per inch) Image resolution. PyLithics works best with 300+ DPI Thresholding Process of converting grayscale images to binary (black/white) Contour Boundary line around objects in the image Hierarchy Parent-child relationships between contours (surfaces contain scars) Morphological Closing Image processing operation to fill small gaps in contours"},{"location":"user-guide/glossary/#archaeological-terms","title":"Archaeological Terms","text":"Cha\u00eene Op\u00e9ratoire Sequence of operations in tool production Reduction Sequence Order of flake removals during knapping Debitage Waste flakes produced during tool manufacture Percussion Striking technique used to remove flakes Platform Preparation Creating suitable striking surface on core Ripple Marks Concentric lines showing force propagation"},{"location":"user-guide/glossary/#data-organization","title":"Data Organization","text":""},{"location":"user-guide/glossary/#file-structure","title":"File Structure","text":"image_id Filename of the source image feature_id Unique identifier for each detected feature within an image parent_id ID of the parent contour (for hierarchical relationships) surface_feature Type of feature (Surface, Scar, Cortex, etc.) processing_timestamp When the analysis was performed"},{"location":"user-guide/glossary/#quality-metrics","title":"Quality Metrics","text":"detection_confidence (0-1) Confidence in the automated detection measurement_accuracy (0-1) Estimated accuracy of measurements processing_notes Automated notes about processing issues validation_required (true/false) Flag indicating manual validation recommended"},{"location":"user-guide/glossary/#units-and-scales","title":"Units and Scales","text":""},{"location":"user-guide/glossary/#measurement-units","title":"Measurement Units","text":"<p>All linear measurements are in millimeters (mm) All area measurements are in square millimeters (mm\u00b2) All angular measurements are in degrees (\u00b0)</p>"},{"location":"user-guide/glossary/#scale-conversion","title":"Scale Conversion","text":"pixels_per_mm Conversion factor from pixels to millimeters scale_reference Scale bar used for conversion pixels_per_mm Conversion factor from pixels to millimeters based on scale bar detection measurement_error (mm) Estimated measurement uncertainty"},{"location":"user-guide/glossary/#statistical-summaries","title":"Statistical Summaries","text":""},{"location":"user-guide/glossary/#assemblage-level-metrics","title":"Assemblage-Level Metrics","text":"assemblage_size Total number of artifacts analyzed mean_length, std_length Mean and standard deviation of technical length mean_width, std_width Mean and standard deviation of technical width size_distribution Classification into size categories (small, medium, large) technology_index Composite measure of technological sophistication"},{"location":"user-guide/glossary/#configuration-terms","title":"Configuration Terms","text":""},{"location":"user-guide/glossary/#processing-parameters","title":"Processing Parameters","text":"threshold_method Algorithm used for image binarization (simple, otsu, adaptive) threshold_value Cutoff value for simple thresholding (0-255) min_contour_area Minimum size for contour detection (pixels) edge_detection_sensitivity Parameter controlling edge detection"},{"location":"user-guide/glossary/#analysis-modules","title":"Analysis Modules","text":"feature_enabled Whether specific analysis modules are active debug_mode Whether diagnostic output is generated output_format Format for data export (CSV, JSON) visualization_options Settings for image output generation"},{"location":"user-guide/glossary/#common-abbreviations","title":"Common Abbreviations","text":"<p>CV - Computer Vision DPI - Dots Per Inch CSV - Comma-Separated Values JSON - JavaScript Object Notation RGB - Red, Green, Blue (color model) API - Application Programming Interface CLI - Command Line Interface YAML - Yet Another Markup Language</p>"},{"location":"user-guide/glossary/#value-ranges","title":"Value Ranges","text":""},{"location":"user-guide/glossary/#typical-ranges-for-stone-tools","title":"Typical Ranges for Stone Tools","text":"<p>Technical Length: 10-200 mm (most flakes 20-80 mm) Technical Width: 8-150 mm (most flakes 15-60 mm) Area: 100-15,000 mm\u00b2 (most flakes 300-3,000 mm\u00b2) Aspect Ratio: 0.5-5.0 (most flakes 1.0-2.5) Scar Count: 0-50 (most surfaces 2-15 scars)</p>"},{"location":"user-guide/glossary/#quality-indicators","title":"Quality Indicators","text":"<p>Good Detection: Circularity 0.3-0.9, Convexity &gt; 0.8 Potential Issues: Aspect ratio &gt; 5.0, Area &lt; 50 mm\u00b2 Manual Review Needed: Scar count &gt; 30, Symmetry &lt; 0.1</p> <p>This glossary provides the foundation for understanding and interpreting PyLithics analysis results.</p>"},{"location":"user-guide/image-requirements/","title":"Image Requirements","text":""},{"location":"user-guide/image-requirements/#overview","title":"Overview","text":"<p>PyLithics works with scanned illustrations of 2D lithic artifacts commonly found in archaeological publications. Understanding the image requirements and drawing conventions will help you achieve the best results.</p>"},{"location":"user-guide/image-requirements/#supported-file-formats","title":"Supported File Formats","text":""},{"location":"user-guide/image-requirements/#accepted-formats","title":"Accepted Formats","text":"<ul> <li>PNG (recommended): Lossless compression, best for line drawings</li> <li>JPG/JPEG: Widely supported, though compression may affect quality</li> <li>TIFF: High quality, larger file sizes</li> </ul>"},{"location":"user-guide/image-requirements/#resolution-requirements","title":"Resolution Requirements","text":"<ul> <li>Optimal: 300 DPI (dots per inch) for best balance of quality and processing speed</li> <li>Supported Range: PyLithics has been tested between 75 DPI (minimum) to 600 DPI (maximum)</li> <li>High Resolution: 600+ DPI works well for archaeological line drawings with default settings</li> <li>Recommended: 300-600 DPI for archaeological illustrations</li> </ul> <p>DPI Processing Intelligence</p> <p>PyLithics automatically reads DPI information from your image files. For archaeological line drawings, the default fixed preprocessing kernels work optimally across all DPI ranges (75-600 DPI). DPI-aware scaling is available but typically not needed for clean line art - it's designed for noisy photographs or heavily degraded scans.</p>"},{"location":"user-guide/image-requirements/#dpi-processing-modes","title":"DPI Processing Modes","text":"<p>Default Mode (Recommended for Archaeological Drawings) - Uses fixed kernel sizes optimized for line drawings - Works consistently across 75-600 DPI range - Preserves fine scar details at high resolution - No DPI scaling applied</p> <p>DPI-Aware Mode (For Noisy Images) - Enable with <code>--enable_dpi_scaling</code> flag - Scales preprocessing kernels based on image DPI - Useful for photographs, degraded scans, or noisy images - Three scaling strategies: conservative, standard, aggressive</p>"},{"location":"user-guide/image-requirements/#drawing-style-guidelines","title":"Drawing Style Guidelines","text":""},{"location":"user-guide/image-requirements/#optimal-drawing-characteristics","title":"Optimal Drawing Characteristics","text":"<p>PyLithics performs best with: - Clean line drawings: Black lines on white background - Clear contrast: Strong black/white separation - Minimal artifacts: No scanning artifacts or shadows - Complete outlines: Closed contours for surfaces</p>"},{"location":"user-guide/image-requirements/#supported-illustration-conventions","title":"Supported Illustration Conventions","text":"<p>Currently, PyLithics is optimized to work with flakes.</p>"},{"location":"user-guide/image-requirements/#surface-representations","title":"Surface Representations","text":"<ul> <li>Dorsal surface: Primary view with scar patterns</li> <li>Ventral surface: Smooth surface view (if present)</li> <li>Platform: Striking platform view (if present)</li> <li>Lateral edges: Side profile views (if present)</li> </ul>"},{"location":"user-guide/image-requirements/#internal-details","title":"Internal Details","text":"<ul> <li>Flake scars: Clear outline definition</li> <li>Cortex areas: Stippling or distinct shading patterns</li> <li>Arrows: Direction indicators for flaking</li> <li>Ripple marks: Concentric lines showing force propagation</li> </ul>"},{"location":"user-guide/image-requirements/#orientation-requirements","title":"Orientation Requirements","text":""},{"location":"user-guide/image-requirements/#standard-archaeological-convention","title":"Standard Archaeological Convention","text":"<p>PyLithics is designed to work with lithic illustrations that follow established archaeological drawing conventions. Lithic illustrators have standardized systems of artifact orientation and proportions that are essential for accurate analysis.</p> <p>Key orientation principles:</p> <ol> <li>Vertical Axis: Perpendicular (orthogonal) to the striking platform</li> <li>Scale: Lithics are normally drawn at 1:1 scale</li> <li>Primary View: Usually the dorsal surface is the principal view</li> <li>Multiple Views: Adjacent surfaces illustrated at 90-degree rotations from the principal view</li> <li>Consistent Orientation: All views maintain the same relative positioning</li> </ol> <p>Critical for Accuracy</p> <p>The vertical axis must be orthogonal to the striking platform. This standardization is crucial for accurate measurements, surface classification, and comparative analysis.</p>"},{"location":"user-guide/image-requirements/#visual-example","title":"Visual Example","text":"<p>For best performance and accurate measurement, images loaded into PyLithics should:</p> <p></p> <p>Example of optimal drawing style and orientation for PyLithics analysis</p>"},{"location":"user-guide/image-requirements/#common-issues-to-avoid","title":"Common Issues to Avoid","text":"<p>\u274c Poor Quality:</p> <ul> <li>Blurry or low-resolution scans</li> <li>Gray or faded lines</li> <li>Incomplete contours</li> <li>Mixed drawing styles</li> </ul> <p>\u2705 Good Quality:</p> <ul> <li>Sharp, clear lines</li> <li>High contrast</li> <li>Complete outlines</li> <li>Consistent style</li> </ul>"},{"location":"user-guide/image-requirements/#example-images","title":"Example Images","text":"<p>PyLithics comes with five sample images for you to experiment with. These images have the following characteristics that work best for PyLithics:</p> <ul> <li>Clean black lines on white background</li> <li>Closed contours for all surfaces</li> <li>Clear scar definitions</li> <li>Consistent line thickness</li> <li>Arrows for flaking direction (optional)</li> </ul> <p> </p>"},{"location":"user-guide/image-requirements/#what-about-ripples","title":"What about ripples?","text":""},{"location":"user-guide/image-requirements/#the-challenge-with-ripple-marks","title":"The Challenge with Ripple Marks","text":"<p>While ripple marks (concentric curved lines) are a traditional way to indicate flaking direction in archaeological illustrations, they present challenges for PyLithics' computer vision algorithms:</p> <p>Issues with ripples:</p> <ul> <li>Detection difficulty: Ripple marks can be mistaken for scar boundaries or surface features</li> <li>Inconsistent representation: Different illustrators draw ripples with varying styles and densities</li> <li>Ambiguous direction: Multiple concentric lines can create uncertainty about the exact force direction</li> <li>Processing interference: Ripples can interfere with accurate contour detection and surface classification</li> </ul> <p>Why arrows work better:</p> <ul> <li>Clear directionality: Arrows provide unambiguous force direction indication</li> <li>Consistent detection: PyLithics is specifically optimized for arrow recognition</li> <li>Clean contours: Arrows don't interfere with surface and scar boundary detection</li> <li>Precise analysis: Enable accurate flaking angle measurements and technological analysis</li> </ul>"},{"location":"user-guide/image-requirements/#solution-lithic-editor-and-annotator","title":"Solution: Lithic Editor and Annotator","text":"<p>For illustrations with ripple marks, we recommend using the Lithic Editor and Annotator tool to:</p> <ol> <li>Remove ripple marks cleanly without affecting scar boundaries</li> <li>Replace with arrows that indicate the same directional information</li> <li>Optimize for PyLithics analysis with clean, arrow-based illustrations</li> </ol>"},{"location":"user-guide/image-requirements/#before-and-after-examples","title":"Before and After Examples","text":"<p>The following examples show how Lithic Editor and Annotator can transform ripple-based illustrations into PyLithics-optimized versions:</p> <p> </p> <p>Example workflow: Original illustration with ripples \u2192 Ripples removed \u2192 Arrows added for optimal PyLithics analysis</p> <p>Lithic Editor Integration</p> <p>The Lithic Editor and Annotator tool is designed specifically to prepare archaeological illustrations for PyLithics analysis. It preserves all morphological information while optimizing directional indicators for computer vision processing.</p>"},{"location":"user-guide/image-requirements/#preparing-your-dataset","title":"Preparing Your Dataset","text":""},{"location":"user-guide/image-requirements/#step-by-step-checklist","title":"Step-by-Step Checklist","text":"<ol> <li>\u2610 Scan at 300 DPI minimum</li> <li>\u2610 Save as PNG or high-quality JPG</li> <li>\u2610 Ensure consistent orientation</li> <li>\u2610 Include scale reference</li> <li>\u2610 Clean up scan artifacts</li> <li>\u2610 Verify contrast levels</li> <li>\u2610 Organize in proper directory structure</li> <li>\u2610 Create metadata CSV</li> </ol>"},{"location":"user-guide/image-requirements/#next-steps","title":"Next Steps","text":"<p>Once your images meet these requirements:</p> <ol> <li>Set up your metadata file</li> <li>Configure PyLithics settings</li> <li>Run your analysis</li> </ol>"},{"location":"user-guide/lithic-editor/","title":"Lithic Editor","text":""},{"location":"user-guide/lithic-editor/#coming-soon","title":"Coming Soon","text":"<p>The PyLithics Lithic Editor is a planned feature that will provide manual editing and correction capabilities for lithic analysis results.</p>"},{"location":"user-guide/lithic-editor/#planned-features","title":"Planned Features","text":""},{"location":"user-guide/lithic-editor/#interactive-editing","title":"Interactive Editing","text":"<ul> <li>Contour adjustment: Manually refine automatically detected boundaries</li> <li>Classification correction: Change surface type assignments</li> <li>Feature addition: Add missed scars or features</li> <li>Feature removal: Delete incorrectly detected features</li> </ul>"},{"location":"user-guide/lithic-editor/#quality-control","title":"Quality Control","text":"<ul> <li>Visual validation: Side-by-side comparison of original and processed images</li> <li>Measurement verification: Check and adjust automated measurements</li> <li>Annotation tools: Add notes and comments to specific features</li> <li>Batch corrections: Apply corrections across multiple similar artifacts</li> </ul>"},{"location":"user-guide/lithic-editor/#integration","title":"Integration","text":"<ul> <li>PyLithics workflow: Seamless integration with existing processing pipeline</li> <li>Data export: Export corrected measurements in standard PyLithics format</li> <li>Version tracking: Maintain history of manual edits</li> <li>Reproducibility: Document all manual interventions</li> </ul>"},{"location":"user-guide/lithic-editor/#use-cases","title":"Use Cases","text":""},{"location":"user-guide/lithic-editor/#research-applications","title":"Research Applications","text":"<ul> <li>Publication quality: Ensure accuracy for published measurements</li> <li>Problematic specimens: Handle artifacts that don't process automatically</li> <li>Teaching tool: Educational platform for learning lithic analysis</li> <li>Method validation: Compare automated vs. manual measurements</li> </ul>"},{"location":"user-guide/lithic-editor/#technical-applications","title":"Technical Applications","text":"<ul> <li>Algorithm improvement: Provide training data for better automation</li> <li>Edge case handling: Develop solutions for challenging specimens</li> <li>Quality assurance: Systematic validation of automated results</li> <li>Error correction: Fix systematic processing issues</li> </ul>"},{"location":"user-guide/lithic-editor/#development-timeline","title":"Development Timeline","text":"<p>This feature is currently in the planning phase. Development will begin based on: - User demand and feedback - Available development resources - Integration complexity assessment - Community contributions</p>"},{"location":"user-guide/lithic-editor/#getting-involved","title":"Getting Involved","text":"<p>If you're interested in the Lithic Editor development:</p> <ol> <li>Express interest: Contact the development team</li> <li>Provide requirements: Share your specific editing needs</li> <li>Beta testing: Volunteer for early testing when available</li> <li>Contributing: Offer development assistance</li> </ol>"},{"location":"user-guide/lithic-editor/#alternative-solutions","title":"Alternative Solutions","text":"<p>While awaiting the Lithic Editor, consider these approaches:</p>"},{"location":"user-guide/lithic-editor/#manual-verification","title":"Manual Verification","text":"<ul> <li>Review all labeled images carefully</li> <li>Document problematic cases</li> <li>Use external image editors for visualization</li> <li>Maintain notes on required corrections</li> </ul>"},{"location":"user-guide/lithic-editor/#configuration-tuning","title":"Configuration Tuning","text":"<ul> <li>Adjust PyLithics settings for better automatic detection</li> <li>Use different thresholding methods</li> <li>Fine-tune detection parameters</li> <li>Enable debug modes to understand processing</li> </ul>"},{"location":"user-guide/lithic-editor/#external-tools","title":"External Tools","text":"<ul> <li>ImageJ/Fiji: Manual measurement and annotation</li> <li>QGIS: Spatial analysis and editing</li> <li>Adobe Illustrator: Vector-based contour editing</li> <li>CAD software: Technical drawing corrections</li> </ul>"},{"location":"user-guide/lithic-editor/#feature-requests","title":"Feature Requests","text":"<p>To influence Lithic Editor development, please:</p> <ol> <li>Open GitHub issues with specific feature requests</li> <li>Describe use cases in detail</li> <li>Provide example images showing needed corrections</li> <li>Suggest interface designs or workflows</li> </ol>"},{"location":"user-guide/lithic-editor/#stay-updated","title":"Stay Updated","text":"<ul> <li>GitHub repository: Watch for development announcements</li> <li>Documentation updates: Check this page for progress</li> <li>Community discussions: Join conversations about features</li> <li>Release notifications: Subscribe to project updates</li> </ul>"},{"location":"user-guide/lithic-editor/#contact","title":"Contact","text":"<p>For questions about the Lithic Editor or to contribute to its development:</p> <ul> <li>GitHub Issues: Report bugs or request features</li> <li>Email: Contact the development team</li> <li>Collaboration: Discuss partnership opportunities</li> </ul> <p>This page will be updated as the Lithic Editor development progresses.</p>"},{"location":"user-guide/metadata-setup/","title":"Metadata Setup","text":""},{"location":"user-guide/metadata-setup/#overview","title":"Overview","text":"<p>The metadata CSV file is essential for linking your lithic images to their scale references. PyLithics uses this information for its automatic scale calibration system, which detects and measures scale bars to convert pixel measurements to real-world units (millimeters).</p>"},{"location":"user-guide/metadata-setup/#csv-file-structure","title":"CSV File Structure","text":"<p>Your metadata CSV must contain these three columns:</p> Column Description Required Example <code>image_id</code> Filename of the lithic image Yes <code>artifact_001.png</code> <code>scale_id</code> Filename of the scale image No* <code>scale_001.png</code> <code>scale</code> Scale measurement in millimeters No* <code>50</code> <p>*Required for scale bar calibration. Optional if using pixel measurements only.</p>"},{"location":"user-guide/metadata-setup/#scale-calibration-methods","title":"Scale Calibration Methods","text":"<p>PyLithics uses a simple two-option calibration system:</p>"},{"location":"user-guide/metadata-setup/#1-scale-bar-detection-recommended","title":"1. Scale Bar Detection (Recommended)","text":"<ul> <li>How it works: Computer vision automatically detects and measures scale bars in scale images</li> <li>Requirements: <code>scale_id</code> and <code>scale</code> columns must be provided</li> <li>Supported formats: Horizontal/vertical bars, segmented bars, bars with tick marks</li> <li>Accuracy: Highest precision for real-world measurements</li> </ul>"},{"location":"user-guide/metadata-setup/#2-pixel-measurements-fallback","title":"2. Pixel Measurements (Fallback)","text":"<ul> <li>How it works: Raw pixel measurements when no scale calibration is available</li> <li>Requirements: None - always works</li> <li>Accuracy: Relative measurements only, no real-world units</li> </ul> <p>Why No DPI Fallback?</p> <p>DPI metadata is unreliable because scanners often don't scan at exact DPI settings, values can be estimated rather than measured, and there's no way to verify accuracy. PyLithics focuses on either precise scale bar measurement or clear pixel-based relative measurements.</p>"},{"location":"user-guide/metadata-setup/#understanding-scale-relationships","title":"Understanding Scale Relationships","text":"<p>Critical for Accuracy</p> <p>Scale images must be scanned at the same DPI as their corresponding lithic images. Mismatched DPI between scales and images will lead to incorrect measurements and compromise your analysis results.</p>"},{"location":"user-guide/metadata-setup/#one-scale-multiple-images","title":"One Scale, Multiple Images","text":"<p>A single scale image can be used for multiple artifacts if they were all drawn at the same scale:</p> <pre><code>image_id,scale_id,scale\nflake_001.png,scale_50.png,50\nflake_002.png,scale_50.png,50\nflake_003.png,scale_50.png,50\n</code></pre>"},{"location":"user-guide/metadata-setup/#individual-scales","title":"Individual Scales","text":"<p>Each artifact can have its own scale if needed:</p> <pre><code>image_id,scale_id,scale\nlarge_biface.png,scale_50.png,50\nsmall_flake.png,scale_5.png,5\nmedium_core.png,scale_20.png,20\n</code></pre>"},{"location":"user-guide/metadata-setup/#mixed-calibration-methods","title":"Mixed Calibration Methods","text":"<p>You can mix calibration methods within a single dataset:</p> <pre><code>image_id,scale_id,scale\nartifact_001.png,scale_10.png,10    # Scale bar detection\nartifact_002.png,,                  # Pixel measurements (empty scale columns)\nartifact_003.png,scale_10.png,10    # Scale bar detection\nartifact_004.png,,                  # Pixel measurements\n</code></pre>"},{"location":"user-guide/metadata-setup/#scale-bar-detection-examples","title":"Scale Bar Detection Examples","text":"<p>PyLithics can detect various scale bar styles:</p> <ul> <li>Simple horizontal/vertical lines</li> <li>Segmented scale bars (alternating black/white segments)</li> <li>Scale bars with tick marks</li> <li>Scale bars with brackets or end markers</li> </ul> <p>Scale Bar Tips</p> <ul> <li>Ensure scale bars are clearly visible with good contrast</li> <li>Black scale bars on white backgrounds work best</li> <li>PyLithics measures the longest dimension (horizontal or vertical)</li> <li>Complex scale bar designs may require manual verification</li> </ul>"},{"location":"user-guide/metadata-setup/#directory-organization","title":"Directory Organization","text":""},{"location":"user-guide/metadata-setup/#standard-structure","title":"Standard Structure","text":"<pre><code>pylithics/\n\u2514\u2500\u2500 data/\n    \u251c\u2500\u2500 meta_data.csv         # Your metadata file\n    \u251c\u2500\u2500 images/               # Lithic illustrations for analysis\n    \u2502   \u251c\u2500\u2500 artifact_001.png\n    \u2502   \u251c\u2500\u2500 artifact_002.png\n    \u2502   \u2514\u2500\u2500 artifact_003.png\n    \u2514\u2500\u2500 scales/               # Scale bar images\n        \u251c\u2500\u2500 scale_001.png\n        \u2514\u2500\u2500 scale_002.png\n</code></pre>"},{"location":"user-guide/metadata-setup/#file-naming-conventions","title":"File Naming Conventions","text":"<p>Proper file naming ensures compatibility across different operating systems and prevents processing errors:</p> <p>\u2705 Good Naming:</p> <ul> <li><code>lithic_001.png</code></li> <li><code>artifact_A1.png</code></li> <li><code>flake_site1_layer2.png</code></li> </ul> <p>Why these work well:</p> <ul> <li>Compatible with all operating systems (Windows, Mac, Linux)</li> <li>Easy to reference in CSV files without escaping</li> <li>Sort properly in file browsers</li> <li>Prevent command-line issues</li> </ul> <p>\u274c Avoid:</p> <ul> <li>Spaces: <code>artifact 001.png</code> \u2192 Can cause parsing errors in CSV and command-line</li> <li>Special characters: <code>artifact#1.png</code> \u2192 May be interpreted as comments or commands</li> <li>Very long names: <code>artifact_from_excavation_unit_4_level_3_find_number_127.png</code> \u2192 Can exceed system path limits</li> </ul> <p>Note: While these naming issues won't stop PyLithics from running, they may cause unexpected behavior, require extra quoting in commands, or create confusion when debugging. Following good naming conventions ensures smooth, predictable processing.</p> <p>Best Practice</p> <p>Use underscores instead of spaces, keep names descriptive but concise, and include sequential numbering for easy sorting.</p>"},{"location":"user-guide/metadata-setup/#csv-file-encoding-issues","title":"CSV File Encoding Issues","text":"<p>Excel CSV UTF-8 Problem</p> <p>Avoid saving CSV files as \"CSV UTF-8\" from Excel - this adds an invisible Byte Order Mark (BOM) character that prevents PyLithics from recognizing column headers.</p> <p>Common Error: <code>Missing required column in metadata: image_id</code> (even when the column exists)</p> <p>Solutions:</p> <ol> <li>Excel Users: Save as \"CSV (Comma delimited) (*.csv)\" instead of \"CSV UTF-8\"</li> <li>Remove BOM: If you already have a UTF-8 CSV with BOM, remove it:    <pre><code># On Mac/Linux\nsed -i.bak '1s/^\\xEF\\xBB\\xBF//' your_metadata.csv\n\n# On Windows (PowerShell)\n(Get-Content your_metadata.csv -Raw) -replace '\\ufeff', '' | Set-Content your_metadata.csv\n</code></pre></li> <li>Use Text Editors: Save CSV files with VS Code, Sublime Text, or similar editors</li> <li>Verify Encoding: Check that your CSV file starts directly with <code>image_id</code>, not <code>\ufeffimage_id</code></li> </ol>"},{"location":"user-guide/metadata-setup/#scale-value-determination","title":"Scale Value Determination","text":""},{"location":"user-guide/metadata-setup/#understanding-the-scale-column","title":"Understanding the Scale Column","text":"<p>The <code>scale</code> value represents how many millimeters the scale bar represents in the real world.</p> <p>Examples:</p> <ul> <li>A 1cm scale bar \u2192 <code>scale: 10</code></li> <li>A 5cm scale bar \u2192 <code>scale: 50</code></li> <li>A 2cm scale bar \u2192 <code>scale: 20</code></li> </ul>"},{"location":"user-guide/metadata-setup/#measuring-unknown-scales","title":"Measuring Unknown Scales","text":"<p>If the scale value is not labeled:</p> <ol> <li>Identify any reference measurements in the publication</li> <li>Measure a known dimension on the artifact</li> <li>Use the ratio to calculate the scale value</li> <li>Verify with multiple measurements</li> </ol>"},{"location":"user-guide/metadata-setup/#missing-scale-images","title":"Missing Scale Images","text":"<p>PyLithics can handle missing scale information:</p>"},{"location":"user-guide/metadata-setup/#automatic-pixel-fallback","title":"Automatic Pixel Fallback","text":"<p>If scale bars aren't available, PyLithics automatically uses pixel measurements:</p> <pre><code>image_id,scale_id,scale\nartifact_001.png,,     # Empty scale columns - will use pixels\nartifact_002.png,,     # Empty scale columns - will use pixels\n</code></pre>"},{"location":"user-guide/metadata-setup/#force-pixel-measurements","title":"Force Pixel Measurements","text":"<p>To disable all calibration and use pixel measurements:</p> <pre><code># Run without any calibration\npylithics --data_dir ./artifacts --meta_file ./metadata.csv --disable_scale_calibration\n</code></pre> <p>Pixel-Only Measurements</p> <p>Without scale calibration, all measurements will be in pixels. This limits comparative analysis between different image sources and prevents real-world metric interpretation.</p> <p>Calibration Method Tracking</p> <p>PyLithics automatically tracks which calibration method was used for each image in the output CSV (<code>calibration_method</code> column: either \"scale_bar\" or \"pixels\"), allowing you to validate measurement accuracy and identify potential issues.</p>"},{"location":"user-guide/metadata-setup/#next-steps","title":"Next Steps","text":"<p>With your metadata file prepared:</p> <ol> <li>Learn basic usage - Run your first analysis</li> <li>Configure settings - Customize processing</li> <li>Understand outputs - Interpret results</li> </ol>"},{"location":"user-guide/outputs/","title":"PyLithics Outputs","text":""},{"location":"user-guide/outputs/#overview","title":"Overview","text":"<p>PyLithics generates multiple types of output files to help you analyze and validate your results. This page describes all the files created during processing and how to interpret them.</p>"},{"location":"user-guide/outputs/#output-directory-structure","title":"Output Directory Structure","text":"<p>After running PyLithics, your output directory will contain:</p> <pre><code>processed/\n\u251c\u2500\u2500 measurements.csv           # Main data output\n\u251c\u2500\u2500 pylithics.log              # Processing log\n\u251c\u2500\u2500 labeled_images/            # Annotated visualizations\n\u2502   \u251c\u2500\u2500 artifact_001_labeled.png\n\u2502   \u2514\u2500\u2500 artifact_002_labeled.png\n\u251c\u2500\u2500 voronoi_diagrams/          # Spatial analysis\n\u2502   \u251c\u2500\u2500 artifact_001_voronoi.png\n\u2502   \u2514\u2500\u2500 artifact_002_voronoi.png\n\u2514\u2500\u2500 arrow_debug/               # Debug output (if enabled)\n    \u251c\u2500\u2500 artifact_001_arrows.png\n    \u2514\u2500\u2500 artifact_002_arrows.png\n</code></pre>"},{"location":"user-guide/outputs/#primary-data-output","title":"Primary Data Output","text":""},{"location":"user-guide/outputs/#measurementscsv","title":"measurements.csv","text":"<p>The main output file containing all quantitative measurements in CSV format.</p>"},{"location":"user-guide/outputs/#data-structure","title":"Data Structure","text":"<p>The CSV is hierarchically organized: - Surfaces: Dorsal, Ventral, Platform, Lateral - Features: Individual scars, cortex areas, retouch zones - Relationships: Parent-child contour associations</p>"},{"location":"user-guide/outputs/#key-columns","title":"Key Columns","text":"<p>Identification - <code>image_id</code>: Source image filename - <code>surface_type</code>: Dorsal, Ventral, Platform, Lateral, or Unknown - <code>surface_feature</code>: Surface, Scar, Cortex, Retouch, etc. - <code>feature_id</code>: Unique identifier within image</p> <p>Scale Calibration Metadata - <code>calibration_method</code>: Method used (\"scale_bar\" or \"pixels\") - <code>pixels_per_mm</code>: Conversion factor applied (null for pixel measurements) - <code>scale_confidence</code>: Detection confidence score (0-1, scale_bar method only)</p> <p>Basic Measurements - <code>technical_length</code>: Platform-to-distal distance (mm) - <code>technical_width</code>: Maximum perpendicular width (mm) - <code>area</code>: Surface area (mm\u00b2) - <code>perimeter</code>: Boundary perimeter (mm) - <code>centroid_x</code>, <code>centroid_y</code>: Center coordinates</p> <p>Shape Properties - <code>aspect_ratio</code>: Length/width ratio - <code>circularity</code>: Shape compactness (0-1) - <code>convexity</code>: Boundary convexity - <code>solidity</code>: Area density</p> <p>Advanced Metrics (configurable) - <code>symmetry_vertical</code>: Vertical balance (0-1) - <code>symmetry_horizontal</code>: Horizontal balance (0-1) - <code>scar_count</code>: Number of child scars - <code>scar_complexity</code>: Adjacency relationships - <code>has_arrow</code>: Arrow detection flag (true/false) - <code>arrow_angle</code>: Flaking direction (degrees) - <code>voronoi_cells</code>: Spatial tessellation count - <code>convex_hull_area</code>: Convex hull area (mm\u00b2) - <code>lateral_convexity</code>: Edge convexity measure</p>"},{"location":"user-guide/outputs/#example-data-row","title":"Example Data Row","text":"<pre><code>image_id,surface_type,surface_feature,calibration_method,pixels_per_mm,scale_confidence,technical_length,technical_width,area,has_arrow,arrow_angle\nartifact_001.png,Dorsal,Surface,scale_bar,25.2,0.95,45.2,32.1,1203.5,false,\nartifact_001.png,Dorsal,Scar,scale_bar,25.2,0.95,12.3,8.7,89.4,true,145.6\nartifact_002.png,Ventral,Surface,pixels,,,1138,812,30421,false,\nartifact_003.png,Dorsal,Surface,pixels,,,1140,809,30378,false,\n</code></pre>"},{"location":"user-guide/outputs/#visualization-outputs","title":"Visualization Outputs","text":""},{"location":"user-guide/outputs/#labeled-images","title":"Labeled Images","text":"<p>Filename pattern: <code>{image_id}_labeled.png</code></p> <p>Content: - Original image with colored overlays - Contour boundaries in different colors - Surface classifications as labels - Arrow indicators (if detected) - Scale reference</p> <p>Color Coding: - Purple <code>RGB(94, 60, 153)</code>: Surface elements (dorsal/ventral/platform/lateral) - Orange <code>RGB(253, 184, 99)</code>: Scar elements - Red <code>RGB(215, 48, 39)</code>: Cortex elements - Mint Green <code>RGB(128, 205, 193)</code>: Lateral edges - Light Purple <code>RGB(178, 171, 210)</code>: Platform marks - Light Blue <code>RGB(145, 191, 219)</code>: Arrows</p>"},{"location":"user-guide/outputs/#voronoi-diagrams","title":"Voronoi Diagrams","text":"<p>Filename pattern: <code>{image_id}_voronoi.png</code></p> <p>Content: - Spatial tessellation of scar centroids - Voronoi cell boundaries - Cell area colorization - Statistical overlays</p> <p>Interpretation: - Dense patterns indicate intensive flaking - Large cells suggest sparse scar distribution - Regular patterns may indicate systematic reduction</p>"},{"location":"user-guide/outputs/#debug-and-diagnostic-outputs","title":"Debug and Diagnostic Outputs","text":""},{"location":"user-guide/outputs/#scale-calibration-debug","title":"Scale Calibration Debug","text":"<p>Location: <code>processed/scale_debug/</code> Enabled by: <code>--scale_debug</code> flag</p> <p>Files generated: - <code>debug_{scale_id}</code>: Scale bar detection visualization with bounding box - Shows detected scale length in pixels and confidence score - Helps troubleshoot scale detection issues</p>"},{"location":"user-guide/outputs/#arrow-detection-debug","title":"Arrow Detection Debug","text":"<p>Location: <code>processed/arrow_debug/</code> Enabled by: <code>--arrow_debug</code> flag</p> <p>Files generated: - <code>{image_id}_arrows.png</code>: Detected arrow overlays - <code>{image_id}_contours.png</code>: All contour hierarchies - <code>{image_id}_candidates.png</code>: Arrow candidates</p>"},{"location":"user-guide/outputs/#processing-log","title":"Processing Log","text":"<p>Filename: <code>pylithics.log</code></p> <p>Content: - Processing timestamps - Configuration settings used - Error messages and warnings - Performance metrics - Feature detection statistics</p> <p>Example log entries: <pre><code>2024-01-15 10:30:15 [INFO] Starting PyLithics analysis\n2024-01-15 10:30:15 [INFO] Configuration: arrow_detection=True, scale_calibration=True, voronoi=True\n2024-01-15 10:30:16 [INFO] Processing artifact_001.png\n2024-01-15 10:30:16 [INFO] Scale bar detected: 1260 pixels, confidence: 0.95, dimensions: 1260x34\n2024-01-15 10:30:16 [INFO] Using scale bar calibration: 25.2 pixels/mm (1260 pixels = 50 mm)\n2024-01-15 10:30:16 [INFO] - Found 15 contours\n2024-01-15 10:30:16 [INFO] - Classified: Dorsal (1), Ventral (1) surfaces\n2024-01-15 10:30:16 [INFO] - Detected 3 arrows\n2024-01-15 10:30:16 [WARNING] - Low contrast in ventral surface\n2024-01-15 10:30:16 [INFO] Converted measurements to millimeters using factor: 25.200\n2024-01-15 10:30:17 [INFO] Processing artifact_002.png\n2024-01-15 10:30:17 [INFO] No scale calibration available, measurements will be in pixels\n2024-01-15 10:30:17 [INFO] Processing complete: 2.1 seconds\n</code></pre></p>"},{"location":"user-guide/outputs/#configuration-dependent-outputs","title":"Configuration-Dependent Outputs","text":""},{"location":"user-guide/outputs/#when-arrow-detection-is-enabled","title":"When Arrow Detection is Enabled","text":"<p>Additional columns in CSV: - <code>has_arrow</code>: Boolean flag - <code>arrow_angle</code>: Direction in degrees - <code>arrow_length</code>: Arrow size (if measurable)</p> <p>Additional visualizations: - Arrow overlays on labeled images - Arrow debug images (if <code>--arrow_debug</code>)</p>"},{"location":"user-guide/outputs/#when-voronoi-analysis-is-enabled","title":"When Voronoi Analysis is Enabled","text":"<p>Additional columns in CSV: - <code>voronoi_cells</code>: Number of Voronoi cells - <code>voronoi_area_mean</code>: Average cell area - <code>voronoi_area_std</code>: Cell area standard deviation</p> <p>Additional files: - Voronoi diagram PNG files - Spatial statistics summary</p>"},{"location":"user-guide/outputs/#when-scar-complexity-is-enabled","title":"When Scar Complexity is Enabled","text":"<p>Additional columns in CSV: - <code>scar_complexity</code>: Adjacency count - <code>adjacent_scars</code>: List of neighboring scar IDs - <code>isolation_index</code>: Spatial isolation measure</p>"},{"location":"user-guide/outputs/#output-validation","title":"Output Validation","text":""},{"location":"user-guide/outputs/#visual-validation","title":"Visual Validation","text":"<ol> <li>Check labeled images: Verify contour detection accuracy</li> <li>Review classifications: Ensure surfaces are correctly identified</li> <li>Validate arrows: Confirm arrow detection and directions</li> <li>Assess completeness: Check for missed features</li> </ol>"},{"location":"user-guide/outputs/#data-validation","title":"Data Validation","text":"<ol> <li>Measurement ranges: Verify values are reasonable</li> <li>Unit consistency: Ensure mm units throughout</li> <li>Missing data: Check for incomplete records</li> <li>Outlier detection: Identify unusual measurements</li> </ol>"},{"location":"user-guide/outputs/#common-validation-checks","title":"Common Validation Checks","text":"<pre><code>import pandas as pd\n\n# Load results\ndf = pd.read_csv('processed/measurements.csv')\n\n# Check measurement ranges\nprint(\"Length range:\", df['technical_length'].min(), \"-\", df['technical_length'].max())\nprint(\"Width range:\", df['technical_width'].min(), \"-\", df['technical_width'].max())\n\n# Check for missing critical measurements\nmissing_length = df['technical_length'].isna().sum()\nprint(f\"Missing length measurements: {missing_length}\")\n\n# Validate aspect ratios\nunrealistic_ratios = df[df['aspect_ratio'] &gt; 10].shape[0]\nprint(f\"Unrealistic aspect ratios: {unrealistic_ratios}\")\n</code></pre>"},{"location":"user-guide/outputs/#working-with-output-data","title":"Working with Output Data","text":""},{"location":"user-guide/outputs/#loading-in-r","title":"Loading in R","text":"<pre><code># Load and explore data\ndata &lt;- read.csv(\"processed/measurements.csv\")\n\n# Surface summary\ntable(data$surface_type)\n\n# Basic statistics\nsummary(data[c(\"technical_length\", \"technical_width\", \"area\")])\n\n# Plot length vs width\nplot(data$technical_length, data$technical_width, \n     xlab=\"Length (mm)\", ylab=\"Width (mm)\",\n     col=as.factor(data$surface_type))\n</code></pre>"},{"location":"user-guide/outputs/#loading-in-python","title":"Loading in Python","text":"<pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load data\ndf = pd.read_csv('processed/measurements.csv')\n\n# Filter for surfaces only\nsurfaces = df[df['surface_feature'] == 'Surface']\n\n# Basic plotting\nplt.figure(figsize=(10, 6))\nplt.scatter(surfaces['technical_length'], surfaces['technical_width'], \n           c=surfaces['surface_type'].astype('category').cat.codes)\nplt.xlabel('Length (mm)')\nplt.ylabel('Width (mm)')\nplt.title('Lithic Dimensions by Surface Type')\nplt.show()\n</code></pre>"},{"location":"user-guide/outputs/#customizing-outputs","title":"Customizing Outputs","text":""},{"location":"user-guide/outputs/#output-format-options","title":"Output Format Options","text":"<pre><code># JSON output instead of CSV\npylithics --data_dir ./data --meta_file ./meta.csv --output_format json\n\n# Custom output directory\npylithics --data_dir ./data --meta_file ./meta.csv --output_dir ./results\n\n# Minimal output (data only)\npylithics --data_dir ./data --meta_file ./meta.csv --no_images\n</code></pre>"},{"location":"user-guide/outputs/#selective-visualization","title":"Selective Visualization","text":"<pre><code># Save only specific visualizations\npylithics --data_dir ./data --meta_file ./meta.csv \\\n         --save_labeled_images \\\n         --no_voronoi\n</code></pre>"},{"location":"user-guide/outputs/#file-management","title":"File Management","text":""},{"location":"user-guide/outputs/#organizing-results","title":"Organizing Results","text":"<pre><code># Create timestamped results\ntoday=$(date +\"%Y%m%d\")\nmkdir results_$today\npylithics --data_dir ./data --meta_file ./meta.csv \\\n         --output_dir ./results_$today\n</code></pre>"},{"location":"user-guide/outputs/#archiving-outputs","title":"Archiving Outputs","text":"<pre><code># Compress results for storage\ntar -czf results_archive.tar.gz processed/\n\n# Keep only CSV data\ncp processed/measurements.csv ./analysis/\nrm -rf processed/\n</code></pre>"},{"location":"user-guide/outputs/#next-steps","title":"Next Steps","text":"<ul> <li>Voronoi Analysis - Understand spatial patterns</li> <li>Troubleshooting - Resolve output issues</li> <li>Glossary - Reference for all metrics</li> </ul>"},{"location":"user-guide/troubleshooting/","title":"Troubleshooting","text":""},{"location":"user-guide/troubleshooting/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"<p>This guide helps you diagnose and solve the most frequent problems when using PyLithics.</p>"},{"location":"user-guide/troubleshooting/#installation-issues","title":"Installation Issues","text":""},{"location":"user-guide/troubleshooting/#python-version-errors","title":"Python Version Errors","text":"<p>Problem: \"Python 3.7+ required\" or compatibility errors</p> <p>Solutions: <pre><code># Check your Python version\npython --version\n\n# Install correct Python version\n# macOS (using Homebrew)\nbrew install python@3.9\n\n# Ubuntu/Debian\nsudo apt-get install python3.9\n\n# Windows - download from python.org\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#package-installation-failures","title":"Package Installation Failures","text":"<p>Problem: <code>pip install .</code> fails with dependency errors</p> <p>Solutions: <pre><code># Upgrade pip first\npip install --upgrade pip\n\n# Install with verbose output to see details\npip install . -v\n\n# Install dependencies manually if needed\npip install opencv-python-headless&gt;=4.8.0\npip install numpy&gt;=1.24.0\npip install pandas&gt;=1.5.0\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#virtual-environment-issues","title":"Virtual Environment Issues","text":"<p>Problem: Virtual environment not activating or packages not found</p> <p>Solutions: <pre><code># Verify virtual environment is active\nwhich python  # Should show path in your venv\n\n# Recreate virtual environment if corrupted\ndeactivate\nrm -rf palaeo/\npython3 -m venv palaeo\nsource palaeo/bin/activate\npip install .\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#image-processing-issues","title":"Image Processing Issues","text":""},{"location":"user-guide/troubleshooting/#no-contours-found","title":"No Contours Found","text":"<p>Problem: \"No contours detected\" or empty results</p> <p>Diagnosis: <pre><code># Enable debug mode to see what's happening\npylithics --data_dir ./data --meta_file ./meta.csv \\\\\\n         --log_level DEBUG --show_thresholded_images\n</code></pre></p> <p>Solutions: <pre><code># Try different thresholding methods\npylithics --data_dir ./data --meta_file ./meta.csv \\\\\\n         --threshold_method otsu\n\n# For poor contrast images\npylithics --data_dir ./data --meta_file ./meta.csv \\\\\\n         --threshold_method adaptive\n\n# Adjust threshold value manually\npylithics --data_dir ./data --meta_file ./meta.csv \\\\\\n         --threshold_method simple --threshold_value 100\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#poor-contour-detection","title":"Poor Contour Detection","text":"<p>Problem: Incomplete or inaccurate contour boundaries</p> <p>Image Quality Checks: - Ensure high contrast (black lines on white background) - Verify resolution is at least 300 DPI - Check for scanning artifacts or noise - Confirm contours are closed/complete</p> <p>Configuration Solutions: <pre><code># In config.yaml, try these adjustments\nthresholding:\\n  method: adaptive\\n  adaptive_block_size: 15\\n  adaptive_constant: 3\\n\\npreprocessing:\\n  denoise: true\\n  morphological_closing: true\\n  closing_kernel_size: 3\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#scale-calculation-errors","title":"Scale Calculation Errors","text":"<p>Problem: Unrealistic measurements (too large/small)</p> <p>Check metadata: <pre><code># Verify your metadata.csv format\\nimage_id,scale_id,scale\\nartifact_001.png,scale_001.png,10  # Scale in millimeters\n</code></pre></p> <p>Common mistakes: - Scale value in centimeters instead of millimeters - Missing or incorrect scale images - Wrong image-scale associations</p>"},{"location":"user-guide/troubleshooting/#configuration-issues","title":"Configuration Issues","text":""},{"location":"user-guide/troubleshooting/#config-file-not-loading","title":"Config File Not Loading","text":"<p>Problem: Configuration changes not taking effect</p> <p>Solutions: <pre><code># Verify config file path\npylithics --data_dir ./data --meta_file ./meta.csv \\\\\\n         --config_file ./config.yaml --log_level DEBUG\n\n# Check YAML syntax\npython -c \\\"import yaml; yaml.safe_load(open('config.yaml'))\\\"\n\n# Use absolute paths if needed\npylithics --data_dir $(pwd)/data --meta_file $(pwd)/meta.csv \\\\\\n         --config_file $(pwd)/config.yaml\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#cli-overrides-not-working","title":"CLI Overrides Not Working","text":"<p>Problem: Command-line arguments ignored</p> <p>Solutions: <pre><code># Verify argument syntax\\npylithics --data_dir ./data --meta_file ./meta.csv \\\\\\n         --threshold_method=otsu  # Use = or space\\n\\n# Check argument spelling\\npylithics --help  # See all available options\n\n# Use debug logging to verify settings\\npylithics --data_dir ./data --meta_file ./meta.csv \\\\\\n         --log_level DEBUG\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#feature-specific-issues","title":"Feature-Specific Issues","text":""},{"location":"user-guide/troubleshooting/#arrow-detection-problems","title":"Arrow Detection Problems","text":"<p>Problem: Arrows not detected or false positives</p> <p>Enable debug mode: ```bash\\npylithics --data_dir ./data --meta_file ./meta.csv \\\\n         --arrow_debug --log_level DEBUG <pre><code>**Check debug images**:\n- Look in `processed/arrow_debug/`\n- Review candidate detection images\n- Verify DPI settings are correct\n\n**Adjust configuration**:\n```yaml\\narrow_detection:\\n  enabled: true\\n  reference_dpi: 300.0  # Match your image DPI\\n  min_area_scale_factor: 0.5  # Lower for smaller arrows\\n  max_area_scale_factor: 15.0  # Higher for larger arrows\\n  min_aspect_ratio: 1.2  # Lower for rounder arrows\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#performance-problems","title":"Performance Problems","text":"<p>Problem: Very slow processing</p> <p>Quick solutions: <pre><code># Disable time-consuming features\\npylithics --data_dir ./data --meta_file ./meta.csv \\\\\\n         --disable_arrow_detection \\\\\\n         --disable_voronoi \\\\\\n         --disable_symmetry\n\n# Process smaller batches\\n# Split your dataset into smaller directories\n\n# Use simpler thresholding\\npylithics --data_dir ./data --meta_file ./meta.csv \\\\\\n         --threshold_method simple\n</code></pre></p> <p>Memory issues: <pre><code># Monitor memory usage\\ntop -p $(pgrep -f pylithics)\\n\\n# Process one image at a time if needed\\n# Create single-image metadata files for large images\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#voronoi-analysis-issues","title":"Voronoi Analysis Issues","text":"<p>Problem: No Voronoi diagrams generated</p> <p>Check requirements: - Surfaces must have \u22653 scars for Voronoi analysis - Voronoi analysis must be enabled in config - Verify scar detection is working</p> <p>Configuration: ```yaml\\nvoronoi_analysis:\\n  enabled: true\\n  min_scars: 3  # Lower if needed\\n  min_surface_area: 50  # Lower for small artifacts <pre><code>## Data Issues\n\n### Missing Output Files\n\n**Problem**: Expected output files not created\n\n**Check permissions**:\n```bash\n# Verify write permissions\\nls -la processed/\\nchmod 755 processed/  # If needed\n</code></pre></p> <p>Check processing log: <pre><code># Review log for errors\\ntail -50 processed/pylithics.log\\n\\n# Look for specific error messages\\ngrep ERROR processed/pylithics.log\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#unrealistic-measurements","title":"Unrealistic Measurements","text":"<p>Problem: Measurements don't match expectations</p> <p>Validation steps: 1. Check scale information in metadata 2. Verify units (should be millimeters) 3. Review labeled images for accuracy 4. Compare with known measurements</p> <p>Debug measurements: <pre><code>import pandas as pd\\n\\n# Load and examine data\\ndf = pd.read_csv('processed/measurements.csv')\\n\\n# Check measurement ranges\\nprint(\\\"Length range:\\\", df['technical_length'].min(), \\\"-\\\", df['technical_length'].max())\\nprint(\\\"Area range:\\\", df['area'].min(), \\\"-\\\", df['area'].max())\\n\\n# Look for outliers\\noutliers = df[df['technical_length'] &gt; 200]  # Adjust threshold\\nprint(\\\"Large artifacts:\\\", outliers[['image_id', 'technical_length']])\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#platform-specific-issues","title":"Platform-Specific Issues","text":""},{"location":"user-guide/troubleshooting/#macos-issues","title":"macOS Issues","text":"<p>OpenCV installation problems: <pre><code># Try installing with conda instead of pip\\nconda install opencv\\n\\n# Or use homebrew version\\nbrew install opencv\\npip install opencv-python-headless\n</code></pre></p> <p>Permission errors: <pre><code># Fix permission issues\\nsudo chown -R $(whoami) /usr/local/lib/python*/site-packages/\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#windows-issues","title":"Windows Issues","text":"<p>PowerShell execution policy: <pre><code># Allow script execution\\nSet-ExecutionPolicy RemoteSigned -Scope CurrentUser\n</code></pre></p> <p>Path length limitations: - Use shorter directory paths - Move project closer to root drive - Enable long path support in Windows</p>"},{"location":"user-guide/troubleshooting/#linux-issues","title":"Linux Issues","text":"<p>Missing system dependencies: <pre><code># Ubuntu/Debian\\nsudo apt-get install python3-dev libopencv-dev\\n\\n# CentOS/RHEL\\nsudo yum install python3-devel opencv-devel\\n\\n# Or use conda environment\\nconda install opencv numpy pandas\n</code></pre></p>"},{"location":"user-guide/troubleshooting/#error-message-guide","title":"Error Message Guide","text":""},{"location":"user-guide/troubleshooting/#filenotfounderror","title":"\\\"FileNotFoundError\\\"","text":"<p>Cause: Missing image or scale files Solution: Check file paths and metadata.csv entries</p>"},{"location":"user-guide/troubleshooting/#valueerror-could-not-convert-string-to-float","title":"\\\"ValueError: could not convert string to float\\\"","text":"<p>Cause: Invalid scale values in metadata Solution: Ensure scale column contains only numbers</p>"},{"location":"user-guide/troubleshooting/#memoryerror","title":"\\\"MemoryError\\\"","text":"<p>Cause: Insufficient RAM for large images Solution: Reduce image size or process in batches</p>"},{"location":"user-guide/troubleshooting/#importerror-no-module-named-cv2","title":"\\\"ImportError: No module named 'cv2'\\\"","text":"<p>Cause: OpenCV not installed Solution: <code>pip install opencv-python-headless</code></p>"},{"location":"user-guide/troubleshooting/#yamlscannerscannererror","title":"\\\"yaml.scanner.ScannerError\\\"","text":"<p>Cause: Invalid YAML syntax in config file Solution: Check indentation and special characters</p>"},{"location":"user-guide/troubleshooting/#performance-optimization","title":"Performance Optimization","text":""},{"location":"user-guide/troubleshooting/#for-large-datasets","title":"For Large Datasets","text":"<pre><code># Minimal processing for speed\\npylithics --data_dir ./large_dataset --meta_file ./meta.csv \\\\\\n         --disable_arrow_detection \\\\\\n         --disable_voronoi \\\\\\n         --disable_symmetry \\\\\\n         --threshold_method simple \\\\\\n         --no_images\n</code></pre>"},{"location":"user-guide/troubleshooting/#memory-management","title":"Memory Management","text":"<pre><code># Process in smaller batches\\nfor batch in batch_*; do\\n    pylithics --data_dir ./$batch --meta_file ./$batch/meta.csv\\n    # Optional: clear temp files\\n    rm -rf ./$batch/processed/debug/\\ndone\n</code></pre>"},{"location":"user-guide/troubleshooting/#disabling-features-for-speed","title":"Disabling Features for Speed","text":"Feature Speed Impact CLI Flag Config Setting Arrow Detection High <code>--disable_arrow_detection</code> <code>arrow_detection.enabled: false</code> Voronoi Analysis Medium <code>--disable_voronoi</code> <code>voronoi_analysis.enabled: false</code> Symmetry Analysis Low <code>--disable_symmetry</code> <code>symmetry_analysis.enabled: false</code> Image Output Medium <code>--no_images</code> N/A"},{"location":"user-guide/troubleshooting/#getting-help","title":"Getting Help","text":""},{"location":"user-guide/troubleshooting/#information-to-provide","title":"Information to Provide","text":"<p>When reporting issues, include:</p> <ol> <li>PyLithics version: <code>pylithics --version</code></li> <li>Python version: <code>python --version</code></li> <li>Operating system: OS and version</li> <li>Command used: Full command line</li> <li>Error message: Complete error text</li> <li>Log file: Contents of pylithics.log</li> <li>Sample data: Minimal example that reproduces issue</li> </ol>"},{"location":"user-guide/troubleshooting/#where-to-get-help","title":"Where to Get Help","text":"<ul> <li>GitHub Issues: Report bugs and get help</li> <li>Documentation: Check other sections of this guide</li> <li>Email: Contact the development team</li> </ul>"},{"location":"user-guide/troubleshooting/#before-reporting","title":"Before Reporting","text":"<ol> <li>Check this troubleshooting guide</li> <li>Search existing GitHub issues</li> <li>Try with sample data provided with PyLithics</li> <li>Test with minimal configuration</li> </ol>"},{"location":"user-guide/troubleshooting/#diagnostic-commands","title":"Diagnostic Commands","text":""},{"location":"user-guide/troubleshooting/#system-check","title":"System Check","text":"<pre><code># Check Python and pip\\npython --version\\npip --version\\n\\n# Check PyLithics installation\\npylithics --help\\n\\n# Verify dependencies\\npython -c \\\"import cv2, numpy, pandas; print('Dependencies OK')\\\"\\n\\n# Test with sample data\\npylithics --data_dir ./pylithics/data --meta_file ./pylithics/data/meta_data.csv\n</code></pre>"},{"location":"user-guide/troubleshooting/#debug-mode","title":"Debug Mode","text":"<p><code>bash\\n# Full debug output\\npylithics --data_dir ./data --meta_file ./meta.csv \\\\\\n         --log_level DEBUG \\\\\\n         --show_thresholded_images \\\\\\n         --arrow_debug</code></p> <p>This will provide maximum information for diagnosing issues.</p>"},{"location":"user-guide/voronoi-analysis/","title":"Voronoi Analysis","text":""},{"location":"user-guide/voronoi-analysis/#overview","title":"Overview","text":"<p>Voronoi analysis in PyLithics provides spatial pattern analysis of scar distributions on lithic surfaces. This advanced feature generates tessellation diagrams that reveal technological patterns and reduction strategies.</p>"},{"location":"user-guide/voronoi-analysis/#what-is-voronoi-analysis","title":"What is Voronoi Analysis?","text":""},{"location":"user-guide/voronoi-analysis/#mathematical-foundation","title":"Mathematical Foundation","text":"<p>A Voronoi diagram divides a plane into regions based on distance to specific points (in our case, scar centroids). Each region contains all points closer to one scar than to any other scar.</p>"},{"location":"user-guide/voronoi-analysis/#archaeological-application","title":"Archaeological Application","text":"<ul> <li>Flaking Intensity: Dense patterns indicate intensive reduction</li> <li>Spatial Organization: Regular patterns suggest systematic flaking</li> <li>Reduction Strategy: Clustering reveals preferred flaking zones</li> <li>Skill Assessment: Regularity may indicate knapper expertise</li> </ul>"},{"location":"user-guide/voronoi-analysis/#enabling-voronoi-analysis","title":"Enabling Voronoi Analysis","text":""},{"location":"user-guide/voronoi-analysis/#configuration","title":"Configuration","text":"<pre><code># In config.yaml\nvoronoi_analysis:\n  enabled: true\n  output_diagrams: true\n  min_scars: 3              # Minimum scars needed for analysis\n  boundary_method: convex   # convex or rectangle\n</code></pre>"},{"location":"user-guide/voronoi-analysis/#command-line","title":"Command Line","text":"<pre><code># Enable Voronoi analysis\npylithics --data_dir ./data --meta_file ./meta.csv\n\n# Disable for faster processing\npylithics --data_dir ./data --meta_file ./meta.csv --disable_voronoi\n</code></pre>"},{"location":"user-guide/voronoi-analysis/#generated-outputs","title":"Generated Outputs","text":""},{"location":"user-guide/voronoi-analysis/#voronoi-diagram-images","title":"Voronoi Diagram Images","text":"<p>Location: <code>processed/voronoi_diagrams/</code> Filename: <code>{image_id}_voronoi.png</code></p> <p>Visual Elements: - Scar centroid points - Voronoi cell boundaries - Color-coded cell areas - Statistical overlays - Scale reference</p>"},{"location":"user-guide/voronoi-analysis/#csv-data-columns","title":"CSV Data Columns","text":"<p>When Voronoi analysis is enabled, additional columns appear in the output CSV:</p> Column Description Units <code>voronoi_cells</code> Number of Voronoi cells count <code>voronoi_area_mean</code> Average cell area mm\u00b2 <code>voronoi_area_std</code> Standard deviation of cell areas mm\u00b2 <code>voronoi_density</code> Scars per unit area scars/mm\u00b2 <code>spatial_distribution</code> Regularity index (0-1) ratio"},{"location":"user-guide/voronoi-analysis/#interpretation-guide","title":"Interpretation Guide","text":""},{"location":"user-guide/voronoi-analysis/#cell-size-patterns","title":"Cell Size Patterns","text":"<p>Large, uniform cells: - Systematic, controlled flaking - Experienced knapper - Planned reduction sequence</p> <p>Small, irregular cells: - Intensive flaking - Opportunistic removal - Possible reworking or resharpening</p> <p>Mixed cell sizes: - Multi-stage reduction - Different flaking episodes - Changing reduction strategies</p>"},{"location":"user-guide/voronoi-analysis/#spatial-organization","title":"Spatial Organization","text":"<p>Regular distribution: - Deliberate scar placement - Efficient core utilization - Systematic reduction strategy</p> <p>Clustered distribution: - Localized intensive flaking - Platform preparation areas - Reworking zones</p> <p>Random distribution: - Opportunistic flaking - Less controlled reduction - Possible expedient technology</p>"},{"location":"user-guide/voronoi-analysis/#convex-hull-analysis","title":"Convex Hull Analysis","text":""},{"location":"user-guide/voronoi-analysis/#what-is-convex-hull","title":"What is Convex Hull?","text":"<p>The convex hull is the smallest convex shape that contains all scar points. It provides:</p> <ul> <li>Total flaking area: Maximum extent of scar distribution</li> <li>Utilization efficiency: How much of available surface was used</li> <li>Shape regularity: Geometric properties of flaking zone</li> </ul>"},{"location":"user-guide/voronoi-analysis/#convex-hull-metrics","title":"Convex Hull Metrics","text":"Metric Description Interpretation <code>convex_hull_area</code> Area of convex hull Total flaking zone <code>hull_perimeter</code> Perimeter of hull Edge utilization <code>hull_solidity</code> Scar area / hull area Flaking efficiency <code>hull_aspect_ratio</code> Length/width of hull Shape preference"},{"location":"user-guide/voronoi-analysis/#configuration-options","title":"Configuration Options","text":""},{"location":"user-guide/voronoi-analysis/#analysis-parameters","title":"Analysis Parameters","text":"<pre><code>voronoi_analysis:\n  enabled: true\n\n  # Minimum requirements\n  min_scars: 3              # Skip if fewer scars\n  min_surface_area: 100     # Skip small surfaces (mm\u00b2)\n\n  # Boundary definition\n  boundary_method: convex   # convex, rectangle, or surface\n  boundary_buffer: 5        # Buffer around scars (mm)\n\n  # Output options\n  output_diagrams: true     # Generate PNG files\n  color_by_area: true       # Color cells by area\n  show_centroids: true      # Mark scar centers\n\n  # Statistical options\n  calculate_density: true   # Spatial density metrics\n  regularity_analysis: true # Distribution regularity\n</code></pre>"},{"location":"user-guide/voronoi-analysis/#visual-customization","title":"Visual Customization","text":"<pre><code>visualization:\n  voronoi:\n    cell_alpha: 0.6         # Cell transparency\n    boundary_color: black   # Cell border color\n    centroid_size: 3        # Point size\n    colormap: viridis       # Color scheme\n</code></pre>"},{"location":"user-guide/voronoi-analysis/#analysis-examples","title":"Analysis Examples","text":""},{"location":"user-guide/voronoi-analysis/#high-skill-reduction","title":"High-Skill Reduction","text":"<p>Characteristics: - Regular cell sizes - Uniform distribution - High hull solidity - Low area standard deviation</p> <p>Interpretation: - Systematic flaking approach - Efficient surface utilization - Controlled reduction sequence - Experienced knapper</p>"},{"location":"user-guide/voronoi-analysis/#opportunistic-flaking","title":"Opportunistic Flaking","text":"<p>Characteristics: - Irregular cell sizes - Clustered distribution - Low hull solidity - High area standard deviation</p> <p>Interpretation: - Expedient flaking strategy - Focus on immediate needs - Less systematic approach - Possibly less experienced</p>"},{"location":"user-guide/voronoi-analysis/#multi-stage-reduction","title":"Multi-Stage Reduction","text":"<p>Characteristics: - Mixed cell patterns - Multiple clustering zones - Moderate hull solidity - Bimodal area distribution</p> <p>Interpretation: - Different reduction episodes - Changing strategies - Tool reuse or resharpening - Complex reduction history</p>"},{"location":"user-guide/voronoi-analysis/#working-with-voronoi-data","title":"Working with Voronoi Data","text":""},{"location":"user-guide/voronoi-analysis/#statistical-analysis-in-r","title":"Statistical Analysis in R","text":"<pre><code># Load data\ndata &lt;- read.csv(\"processed/measurements.csv\")\n\n# Filter for surfaces with Voronoi analysis\nvoronoi_data &lt;- data[!is.na(data$voronoi_cells), ]\n\n# Summary statistics\nsummary(voronoi_data$voronoi_area_mean)\nsummary(voronoi_data$voronoi_density)\n\n# Compare between surface types\naggregate(voronoi_density ~ surface_type, voronoi_data, mean)\n\n# Plot density vs. regularity\nplot(voronoi_data$voronoi_density, voronoi_data$spatial_distribution,\n     xlab=\"Scar Density\", ylab=\"Spatial Regularity\",\n     main=\"Flaking Patterns\")\n</code></pre>"},{"location":"user-guide/voronoi-analysis/#python-analysis","title":"Python Analysis","text":"<pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load and filter data\ndf = pd.read_csv('processed/measurements.csv')\nvoronoi_df = df[df['voronoi_cells'].notna()]\n\n# Density distribution\nplt.figure(figsize=(10, 6))\nsns.histplot(voronoi_df['voronoi_density'], bins=20)\nplt.xlabel('Scar Density (scars/mm\u00b2)')\nplt.title('Distribution of Flaking Density')\nplt.show()\n\n# Regularity by surface type\nsns.boxplot(data=voronoi_df, x='surface_type', y='spatial_distribution')\nplt.ylabel('Spatial Regularity')\nplt.title('Flaking Regularity by Surface Type')\nplt.show()\n</code></pre>"},{"location":"user-guide/voronoi-analysis/#troubleshooting-voronoi-analysis","title":"Troubleshooting Voronoi Analysis","text":""},{"location":"user-guide/voronoi-analysis/#common-issues","title":"Common Issues","text":"<p>No Voronoi diagrams generated: - Check that surfaces have \u22653 scars - Verify <code>voronoi_analysis.enabled: true</code> in config - Ensure output directory has write permissions</p> <p>Unrealistic cell areas: - Verify scale information in metadata - Check for duplicate scar centroids - Review contour detection accuracy</p> <p>Missing data columns: - Confirm Voronoi analysis is enabled - Check for processing errors in log file - Verify minimum requirements are met</p>"},{"location":"user-guide/voronoi-analysis/#performance-considerations","title":"Performance Considerations","text":"<pre><code># For large datasets, disable Voronoi if not needed\npylithics --data_dir ./large_dataset --meta_file ./meta.csv \\\n         --disable_voronoi\n\n# Or process subset first\npylithics --data_dir ./test_sample --meta_file ./test_meta.csv\n</code></pre>"},{"location":"user-guide/voronoi-analysis/#archaeological-case-studies","title":"Archaeological Case Studies","text":""},{"location":"user-guide/voronoi-analysis/#levallois-technology","title":"Levallois Technology","text":"<p>Expected patterns: - Regular cell distribution - High spatial organization - Systematic centripetal flaking - Efficient surface utilization</p>"},{"location":"user-guide/voronoi-analysis/#expedient-technology","title":"Expedient Technology","text":"<p>Expected patterns: - Irregular cell sizes - Opportunistic distribution - Lower spatial organization - Variable surface utilization</p>"},{"location":"user-guide/voronoi-analysis/#blade-production","title":"Blade Production","text":"<p>Expected patterns: - Linear cell arrangements - Parallel flaking zones - Regular width patterns - High aspect ratio hulls</p>"},{"location":"user-guide/voronoi-analysis/#research-applications","title":"Research Applications","text":""},{"location":"user-guide/voronoi-analysis/#comparative-studies","title":"Comparative Studies","text":"<ul> <li>Inter-site variation: Compare flaking strategies</li> <li>Temporal change: Track technological evolution</li> <li>Skill assessment: Quantify knapping expertise</li> <li>Cultural attribution: Identify technological traditions</li> </ul>"},{"location":"user-guide/voronoi-analysis/#statistical-methods","title":"Statistical Methods","text":"<ul> <li>Cluster analysis: Group similar patterns</li> <li>ANOVA: Test between-group differences</li> <li>Regression: Model relationships</li> <li>Multivariate analysis: Integrate multiple metrics</li> </ul>"},{"location":"user-guide/voronoi-analysis/#next-steps","title":"Next Steps","text":"<ul> <li>Troubleshooting - Resolve analysis issues</li> <li>Glossary - Reference for spatial metrics</li> <li>CLI Commands - Configuration options</li> </ul>"}]}